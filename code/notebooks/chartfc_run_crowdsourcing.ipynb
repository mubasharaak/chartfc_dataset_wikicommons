{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18dd0a52",
   "metadata": {},
   "source": [
    "#### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406f027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages \n",
    "\n",
    "import bs4 \n",
    "import boto3\n",
    "import botocore\n",
    "import botocore.exceptions\n",
    "import copy\n",
    "import dns\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "import random\n",
    "import requests\n",
    "import uuid\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5414f1",
   "metadata": {},
   "source": [
    "## Overview \n",
    "This notebook executes the crowdsourcing experiments for the three different tasks \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103ec833",
   "metadata": {},
   "source": [
    "1. <strong>Generate tasksets </strong>\n",
    "\n",
    "\n",
    "2. <strong>Label gold tasks </strong>\n",
    "\n",
    "\n",
    "3. <strong>Sent tasks to Mechanical Turk for annotation</strong> \n",
    "\n",
    "\n",
    "4. <strong>Frequently update task with workers' answers</strong> \n",
    "\n",
    "Set the following variables first:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8706307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing all data files for crowdsourcing\n",
    "data_folder = ''\n",
    "\n",
    "# Folder containing all config files for crowdsourcing\n",
    "config_folder = ''\n",
    "\n",
    "# Set path to .json file with crowdsourcing qualification tests\n",
    "path_qualification_tests = ''\n",
    "\n",
    "# Set task type as one of the following: 'table_annotation', 'claim_generation', 'adjusted_claim_annotation'\n",
    "task_type = ''\n",
    "\n",
    "# Set to 1 if crowdsourcing tasks in production should be created, else 0 for test\n",
    "create_hits_in_production = 0\n",
    "\n",
    "# Set 1 if current taskSet (if existing) should be updated\n",
    "update_tasksets = 0\n",
    "\n",
    "# Set path to db credentials, used for storing crowdsourcing tasks and results \n",
    "path_mongodb_credentials = ''\n",
    "\n",
    "# Set path to amazon credentials saved in a .json file\n",
    "path_amazon_credentials = ''\n",
    "\n",
    "# Set Amazon mturk endpoint used for crowdsourcing experiments\n",
    "mturk_endpoint = ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b5cb6a",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46cf9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_qualification_tests,'r') as f:\n",
    "    qualification_tests = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145bd715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB \n",
    "\n",
    "with open(path_mongodb_credentials,'r') as f:\n",
    "    mongodb_credentials = json.load(f)\n",
    "\n",
    "# Connect to MTurk and MongoDB\n",
    "db_client = pymongo.MongoClient(mongodb_credentials[\"connection_string\"]) # connecting to database\n",
    "db = db_client['pubhealth']\n",
    "\n",
    "hit_result_collection = db.hit_results if create_hits_in_production else db.hit_results_sandbox\n",
    "\n",
    "mt = MTurk()\n",
    "mt.launch_client(production = create_hits_in_production)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b8179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mturk client\n",
    "\n",
    "class MTurk():\n",
    "\n",
    "    def __init__(self):\n",
    "        with open(path_amazon_credentials)  as f: # get the credentials from AMT \n",
    "            cfg = json.load(f)\n",
    "\n",
    "        self.access_key = cfg['access_key']\n",
    "        self.secret_key = cfg['secret_key']\n",
    "        \n",
    "        self.environments = {\n",
    "            \"production\": {\n",
    "                \"endpoint\": mturk_endpoint, # set mturk endpoint\n",
    "                \"preview\": \"https://www.mturk.com/mturk/preview\"\n",
    "            },\n",
    "            \"sandbox\": {\n",
    "                \"endpoint\": mturk_endpoint, # set mturk endpoint\n",
    "                \"preview\": \"https://workersandbox.mturk.com/mturk/preview\"\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def launch_client(self, production = False):\n",
    "        self.mturk_environment = self.environments[\"production\"] if production else self.environments[\"sandbox\"]\n",
    "        try:\n",
    "            session = boto3.Session(profile_name='mturk')\n",
    "        except botocore.exceptions.ProfileNotFound as e:\n",
    "            session = boto3.Session(\n",
    "                profile_name='mturk',\n",
    "                aws_access_key_id  = self.access_key,\n",
    "                aws_secret_access_key  = self.secret_key\n",
    "            )\n",
    "        self.client = session.client(\n",
    "            service_name= 'mturk',\n",
    "            region_name= 'us-east-1',\n",
    "            endpoint_url= self.mturk_environment['endpoint'],\n",
    "        )\n",
    "        print(self.client.get_account_balance()['AvailableBalance'])\n",
    "\n",
    "    def create_hit(self, html_layout, **TaskAttributes):\n",
    "        QUESTION_XML = \"\"\"...\"\"\"\n",
    "        question_xml = QUESTION_XML.format(html_layout)\n",
    "\n",
    "        response = self.client.create_hit(\n",
    "            **TaskAttributes,\n",
    "            Question=question_xml\n",
    "        )\n",
    "\n",
    "        return response\n",
    "\n",
    "    def get_hit_status(self, HITId):\n",
    "        hit = self.client.get_hit(HITId=HITId)\n",
    "        hit_status = hit['HIT']['HITStatus']\n",
    "        return hit_status\n",
    "\n",
    "    def get_hit_answers(self, HITId, approve=False):\n",
    "\n",
    "        # Get list and number of Assignments that have been completed\n",
    "        hit_assignmentsList = self.client.list_assignments_for_hit(\n",
    "            HITId=HITId,\n",
    "            AssignmentStatuses=['Submitted','Approved']\n",
    "        )\n",
    "\n",
    "        assignments = hit_assignmentsList['Assignments']\n",
    "\n",
    "        # Get details and results of each Assignment and add to answers array\n",
    "        answers = []\n",
    "        for assignment in assignments:\n",
    "            worker_id = assignment['WorkerId']\n",
    "            assignment_id = assignment['AssignmentId']\n",
    "\n",
    "            answer_dict = xmltodict.parse(assignment['Answer'])['QuestionFormAnswers']['Answer']\n",
    "            values = {}\n",
    "            for entry in answer_dict:\n",
    "                try:\n",
    "                    values[entry['QuestionIdentifier']] = json.loads(entry['FreeText'])\n",
    "                except ValueError:\n",
    "                    values[entry['QuestionIdentifier']] = entry['FreeText']\n",
    "                except TypeError:\n",
    "                    values[entry['QuestionIdentifier']] = None\n",
    "\n",
    "            answer = {\n",
    "                'worker_id' : worker_id,\n",
    "                'assignment_id' : assignment_id,\n",
    "                'values' : values,\n",
    "                'HITId' : HITId\n",
    "            }\n",
    "            answers.append(answer)\n",
    "            \n",
    "            if approve:\n",
    "                # Approve or not assignments\n",
    "                if assignment['AssignmentStatus'] == 'Submitted':\n",
    "                    self.client.approve_assignment(\n",
    "                        AssignmentId = assignment_id,\n",
    "                        OverrideRejection = False\n",
    "                    )\n",
    "                    \n",
    "        return answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ed9d5a",
   "metadata": {},
   "source": [
    "### Functions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eace9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_highest_table = 1\n",
    "\n",
    "def select_table(table_list: list, claim_id: str) -> dict:\n",
    "    # select the first table in list which fullfills certain criteria\n",
    "    \n",
    "    for table in table_list: \n",
    "#         check if table has been annotated before (check in hit_results.references)\n",
    "        try:\n",
    "            if second_highest_table:\n",
    "                query = {'timestamp': {'$gte': datetime(2021, 6, 23)}}\n",
    "                query['references.claim_db_id'] = claim_id\n",
    "                query['type'] = \"table_annotation\"\n",
    "                query['references.table.rows_list'] = table[\"rows_list\"]\n",
    "                # todo: add that this entry has not been deleted before assignment was == 3 due to issues\n",
    "                \n",
    "                if list(hit_result_collection.find(query)) != []:\n",
    "                    print(\"table has been used before is therefore skipped\")\n",
    "                    continue\n",
    "        except Exception as e: \n",
    "            print(f\"Following error occurred during MongoDB querying: {e}\")\n",
    "    \n",
    "        if len(table[\"rows_list\"]) > 15: \n",
    "            continue\n",
    "        elif (table[\"header_horizontal\"] and len(table[\"header_horizontal\"])>10):\n",
    "            continue\n",
    "        elif (table[\"header_vertical\"] and len(table[\"header_vertical\"])>10):\n",
    "            continue\n",
    "            \n",
    "        cell_len = [len(cell) for row in table[\"rows_list\"] for cell in row] # if one cell has more than 1k characters, skip\n",
    "        if cell_len and max(cell_len) > 100:\n",
    "#             print(\"cell too long\")\n",
    "            continue\n",
    "        \n",
    "        col_len = [len(row) for row in table[\"rows_list\"]] # if ten or more columns, skip \n",
    "        if col_len and max(col_len) > 15:\n",
    "            continue\n",
    "        \n",
    "        if table[\"header_horizontal\"]: # if one header cell has more than 100 characters, skip\n",
    "            header_h_len = [len(cell) for cell in table[\"header_horizontal\"]]\n",
    "            if max(header_h_len) > 100:\n",
    "                continue\n",
    "                \n",
    "        if table[\"header_vertical\"]: # if one header cell has more than 100 characters, skip\n",
    "            header_v_len = [len(cell) for cell in table[\"header_vertical\"]]\n",
    "            if max(header_v_len) > 100:\n",
    "                continue\n",
    "            \n",
    "        return table \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0adcb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSingleInstances = 1 #MAX TIMES ANY REFERENCE APPEARS AMONG THE TASK SETS\n",
    "\n",
    "def get_random_task(counter, n, non_gd_tasks):\n",
    "    \"\"\"Returns n random tasks of format (task, index) from list non_gd_tasks\"\"\"\n",
    "    \n",
    "    task_seq = []\n",
    "    p = [max(maxSingleInstances-c,0.0001) for c in counter] # indexes of samples which can be used for task generation \n",
    "    p = [pp/sum(p) for pp in p]\n",
    "    indexes = np.random.choice( # random choice of entries (given some constraints)\n",
    "        a = list(range(len(non_gd_tasks))),\n",
    "        size=n,\n",
    "        replace=False, \n",
    "        p=p # samples used before in other tasks => probability set to 0 so that they are not chosen twice\n",
    "    )        \n",
    "\n",
    "    for i in indexes:\n",
    "        task = non_gd_tasks[i]\n",
    "        task_seq.append((task,i))\n",
    "    \n",
    "    return task_seq\n",
    "\n",
    "\n",
    "def get_random_gd_task(n, gd_tasks):\n",
    "    \"\"\"Returns a sub-list of gd_tasks with n entries\"\"\"\n",
    "    return random.sample(gd_tasks, n)\n",
    "\n",
    "\n",
    "def generate_taskset(counter, non_gd_tasks, gd_tasks, n=(5,2)): # set the number of non-gold labelled tasks (e.g. 5) and gold labelled task (e.g. 2)\n",
    "    '''\n",
    "    counter = a counter which keeps track of how many times each reference was retrieved\n",
    "    n = (x,y) where x = number of non_gd references and y = number of gd references\n",
    "    '''\n",
    "    taskSet = []\n",
    "    \n",
    "    task = get_random_task(counter, n[0], non_gd_tasks) # returns list of (index, sample)\n",
    "    taskSet = [r for (r,i) in task] # pairs reference,index are generated here, so that we can update the counter later\n",
    "    taskSet.extend(get_random_gd_task(n[1], gd_tasks))\n",
    "    \n",
    "    random.shuffle(taskSet) # gold standard should occur anywhere\n",
    "    \n",
    "    return taskSet, [i for (p,i) in task] # indixes returned to update counter\n",
    "\n",
    "\n",
    "def generate_taskset_no_gold(counter, non_gd_tasks, n=5):\n",
    "    \"\"\"\n",
    "    Generates taskset of n (default = 5) tasks and updates counter,\n",
    "    so that a task appears only 'maxSingleInstances'-times in a taskSet\n",
    "    \"\"\"\n",
    "    task_index_set = get_random_task(counter, n, non_gd_tasks) # returns list of (index, sample)\n",
    "    taskSet = [r for (r,i) in task_index_set] # tasks extracted from the pairs of (task, index)\n",
    "    \n",
    "    return taskSet, [i for (p,i) in task_index_set] # indixes returned to update counter\n",
    "\n",
    "\n",
    "def generate_taskset_w_ids(non_gd_tasks, gd_tasks) -> list:\n",
    "    \"\"\"\n",
    "    Function to generate TaskSets given gold standards and other samples \n",
    "    \"\"\"\n",
    "    taskSets = []\n",
    "    counter = [0]*len(non_gd_tasks) # keeping track if sample has been used before \n",
    "\n",
    "    while (any([c < maxSingleInstances for c in counter])):\n",
    "        # generate task set with some random samples\n",
    "        taskSet, indexes = generate_taskset(counter, non_gd_tasks, gd_tasks) \n",
    "        taskSetIDd = {\n",
    "            '_id': str(uuid.uuid4()),\n",
    "            'taskSet' : taskSet\n",
    "        }\n",
    "        taskSets.append(taskSetIDd) # add created taskSet with ID to list of taskSets \n",
    "        for i in indexes:\n",
    "            # increase counter for samples added, so that they only appear 'maxSingleInstances'-times in a taskSet\n",
    "            counter[i] = counter[i] + 1 \n",
    "    \n",
    "    return taskSets, counter\n",
    "\n",
    "\n",
    "def generate_taskset_w_ids_no_gold(non_gd_tasks, n = 5) -> list:\n",
    "    \"\"\"\n",
    "    Function to generate TaskSets given samples but without gold labelled samples \n",
    "    n (int): number of non_gold entries per taskSet\n",
    "    \"\"\"\n",
    "    task_set_list = []\n",
    "    counter = [0]*len(non_gd_tasks) # keeping track if sample has been used before \n",
    "\n",
    "    while (any([c < maxSingleInstances for c in counter])): # iterate as long as any sample in non_gd_tasks as not been used\n",
    "        # generate task set with some random samples\n",
    "        task_set, indexes = generate_taskset_no_gold(counter, non_gd_tasks, n) \n",
    "        task_set_w_id = {\n",
    "            '_id': str(uuid.uuid4()),\n",
    "            'taskSet' : task_set\n",
    "        }\n",
    "        \n",
    "        task_set_list.append(task_set_w_id) # add created taskSet with ID to list of taskSets \n",
    "        for i in indexes:\n",
    "            # increase counter for samples added, so that they only appear 'maxSingleInstances'-times in a taskSet\n",
    "            counter[i] = counter[i] + 1 \n",
    "    \n",
    "    return task_set_list, counter\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cee21c4",
   "metadata": {},
   "source": [
    "### 1. Generation of task sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacf5681",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data from MongoDB database\n",
    "\n",
    "if task_type == \"adjusted_claim_annotation\":\n",
    "    claim_col = db.claim_generation\n",
    "    cursor =  claim_col.find({})\n",
    "    df = pd.DataFrame(list(cursor))\n",
    "\n",
    "else:\n",
    "    claim_col = db.final_dataset\n",
    "    if task_type == \"claim_generation\":\n",
    "        cursor =  claim_col.find({\"table_relevant\": {'$ne': None}})\n",
    "    else:\n",
    "        cursor =  claim_col.find({})\n",
    "        \n",
    "    df = pd.DataFrame(list(cursor)) \n",
    "    \n",
    "print(f\"Length of test set: {len(df)}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd65c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_table_claim_generation(table_list: list, claim_id: str) -> dict:\n",
    "    # select the first table in list which fullfills certain criteria\n",
    "    \n",
    "    tables_for_generation = []\n",
    "    for table in table_list: \n",
    "#         check if for table 'table' a claim has been generated before\n",
    "        try:\n",
    "#             query = {} #todo filtering => checkout of an entry for this claim exists in claim_gen collection\n",
    "#             query['type'] = \"claim_generation\"\n",
    "#             query['references.claim_db_id'] = claim_id\n",
    "#             query['references.table.rows_list'] = table[\"rows_list\"]\n",
    "            \n",
    "#             if list(hit_result_collection.find(query)) == []:\n",
    "#                 tables_for_generation.append(table)\n",
    "            \n",
    "            query = {\"initial_claim_id\": claim_id}\n",
    "            query[\"table.id\"] = table[\"id\"]\n",
    "            gen_claim_col_list = list(gen_claim_col.find(query))\n",
    "            if gen_claim_col_list == [] or len(gen_claim_col_list)<2:\n",
    "                tables_for_generation.append(table)\n",
    "                \n",
    "        except Exception as e: \n",
    "            print(f\"Following error occurred during MongoDB querying: {e}\")\n",
    "    \n",
    "    return tables_for_generation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9014fd21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If code being executed for task \"claim_generation\", execute this code\n",
    "\n",
    "if task_type == \"claim_generation\":\n",
    "\n",
    "    # Generating tasks with the following template: \n",
    "    # saving to json file \n",
    "    \n",
    "    gen_claim_col = db.claim_generation\n",
    "    table_column = \"table_relevant\" # TODO later use tables from 1st task results => after majority filtering\n",
    "\n",
    "    if update_tasksets:\n",
    "        task_template = {\n",
    "            \"claim_db_id\": \"\",\n",
    "            \"claim\": \"\",\n",
    "            \"table\": {\n",
    "                \"id\": \"\",\n",
    "                \"url\": \"\",\n",
    "                \"caption\": \"\",\n",
    "                \"header_horizontal\": \"\", \n",
    "                \"header_vertical\": \"\", \n",
    "                \"rows_list\": \"\", \n",
    "                \"html_table\": \"\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Iterate over all test entries, convert and save in json \n",
    "        task_list = []\n",
    "        for index, row in df.iterrows():\n",
    "            if not row[table_column] or len(row[table_column])==0:\n",
    "                print(\"skip\")\n",
    "                continue\n",
    "\n",
    "            db_table_list = select_table_claim_generation(row[table_column], str(row[\"_id\"]))\n",
    "            if not db_table_list or db_table_list==[]: \n",
    "                print(\"skip\")\n",
    "                continue \n",
    "            \n",
    "            for db_table in db_table_list:\n",
    "                task = copy.deepcopy(task_template)\n",
    "                task[\"claim_db_id\"] = str(row[\"_id\"])\n",
    "                task[\"claim\"] = row[\"claim\"]\n",
    "\n",
    "                table = db_table\n",
    "                table[\"id\"] = str(db_table[\"id\"])\n",
    "                if \"_id\" in table : table.pop('_id')\n",
    "\n",
    "    #             task[\"table\"] = row[\"table\"] #TODO => later uncomment!!!\n",
    "                task[\"table\"] = table\n",
    "                task_list.append(task)\n",
    "\n",
    "\n",
    "        print(f\"{len(task_list)} tasks in total created.\\n\")\n",
    "\n",
    "        path = os.path.join(data_folder, \"TaskSets/pre_tasksets_{}.json\".format(task_type))\n",
    "        print(f\"Saving generated task list at path {path}.\\n\")\n",
    "\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as file:\n",
    "            json.dump(task_list, file, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56837190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If code being executed for task \"table_annotation\", execute this code\n",
    "\n",
    "if task_type == \"adjusted_claim_annotation\":\n",
    "\n",
    "    # Generating tasks with the following template: \n",
    "    # saving to json file \n",
    "\n",
    "    table_column = \"table\"\n",
    "    task_temp_provided = True\n",
    "\n",
    "    if update_tasksets:\n",
    "        task_template = {\n",
    "            \"claim_db_id\": \"\",\n",
    "            \"claim\": \"\",\n",
    "            \"label\": \"\",\n",
    "            \"table\": {\n",
    "                \"id\": \"\",\n",
    "                \"url\": \"\",\n",
    "                \"caption\": \"\",\n",
    "                \"header_horizontal\": \"\", \n",
    "                \"header_vertical\": \"\", \n",
    "                \"rows_list\": \"\", \n",
    "                \"html_table\": \"\"\n",
    "            },\n",
    "            \"g_id\": -1\n",
    "        }\n",
    "\n",
    "        # Iterate over all test entries, convert and save in json \n",
    "        task_list = []\n",
    "        for index, row in df.iterrows():\n",
    "#             check if this claim exists with {type: \"adjusted_claim_annotation\"} already in hit_results \n",
    "            if list(hit_result_collection.find({'type': \"adjusted_claim_annotation\", \"references.claim_db_id\": str(row[\"_id\"])}))!=[]:\n",
    "                continue \n",
    "            \n",
    "            task = copy.deepcopy(task_template)\n",
    "            task[\"claim_db_id\"] = str(row[\"_id\"])\n",
    "            task[\"claim\"] = row[\"claim\"]\n",
    "            task[\"label\"] = row[\"label\"]\n",
    "            task[\"table\"] = row[\"table\"]\n",
    "\n",
    "            task_list.append(task)\n",
    "\n",
    "\n",
    "        print(f\"{len(task_list)} tasks in total created.\\n\")\n",
    "\n",
    "        path = os.path.join(data_folder, \"TaskSets/pre_tasksets_{}.json\".format(task_type))\n",
    "        print(f\"Saving generated task list at path {path}.\\n\")\n",
    "\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as file:\n",
    "            json.dump(task_list, file, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1949715",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If code being executed for task \"table_annotation\", execute this code\n",
    "\n",
    "if task_type == \"table_annotation\":\n",
    "    # Generating tasks with the following template: \n",
    "    # saving to json file \n",
    "\n",
    "    table_column = \"tables\"\n",
    "    task_temp_provided = True\n",
    "\n",
    "    if update_tasksets:\n",
    "        task_template = {\n",
    "            \"claim_db_id\": \"\",\n",
    "            \"claim\": \"\",\n",
    "            \"label\": \"\",\n",
    "            \"table\": {\n",
    "                \"id\": \"\",\n",
    "                \"url\": \"\",\n",
    "                \"caption\": \"\",\n",
    "                \"header_horizontal\": \"\", \n",
    "                \"header_vertical\": \"\", \n",
    "                \"rows_list\": \"\", \n",
    "                \"html_table\": \"\"\n",
    "            },\n",
    "            \"g_id\": -1\n",
    "        }\n",
    "\n",
    "        # Iterate over all data entries, create tasks for them and save in json file  \n",
    "        task_list = []        \n",
    "        for index, row in df.iterrows():\n",
    "            if not row[table_column] or len(row[table_column])==0:\n",
    "                continue\n",
    "\n",
    "            task = copy.deepcopy(task_template) # copy the task template and fillout the empty fields\n",
    "            task[\"claim_db_id\"] = str(row[\"_id\"])\n",
    "            task[\"claim\"] = row[\"claim\"]\n",
    "            task[\"label\"] = row[\"label\"]\n",
    "            \n",
    "            if not task_temp_provided:\n",
    "                table = copy.deepcopy(task_template[\"table\"])\n",
    "                db_table = select_table(row[table_column], task[\"claim_db_id\"]) # select first table in list fulfilling requirments\n",
    "                if not db_table: \n",
    "                    print(\"skip\")\n",
    "                    continue \n",
    "\n",
    "                table[\"id\"] = str(db_table[\"id\"]) \n",
    "                table[\"url\"] = db_table[\"url\"] \n",
    "                table[\"caption\"] = db_table[\"caption\"]\n",
    "                table[\"header_horizontal\"] = db_table[\"header_horizontal\"]\n",
    "                table[\"header_vertical\"] = db_table[\"header_vertical\"]\n",
    "                table[\"rows_list\"] = db_table[\"rows_list\"]\n",
    "                table[\"html_table\"] = db_table[\"html_table\"] #     TODO: adjust html table here!!!\n",
    "            else: \n",
    "                db_table = select_table(row[table_column], task[\"claim_db_id\"]) # select from lists of tables, the one which should be send to AMT\n",
    "                if not db_table: \n",
    "                    print(\"skip\")\n",
    "                    continue \n",
    "                table = db_table\n",
    "                table[\"id\"] = str(db_table[\"id\"]) \n",
    "                \n",
    "            task[\"table\"] = table\n",
    "            task_list.append(task) # append the created task to the task_list list \n",
    "\n",
    "        print(f\"{len(task_list)} tasks in total created.\\n\")\n",
    "\n",
    "        path = os.path.join(data_folder, \"TaskSets/pre_tasksets_{}.json\".format(task_type)) \n",
    "        print(f\"Saving generated task list at path {path}.\\n\")\n",
    "\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as file: # save the list of tasks given path\n",
    "            json.dump(task_list, file, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debb27b2",
   "metadata": {},
   "source": [
    "#### Split tasks in gold and non-gold samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73893a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "golden_standard_quota = 20 \n",
    "\n",
    "if update_tasksets and task_type in [\"table_annotation\", \"adjusted_claim_annotation\"]: \n",
    "    with open(os.path.join(data_folder, \"TaskSets/pre_tasksets_{}.json\".format(task_type)), \"rb\") as file: \n",
    "        task_list = json.load(file)\n",
    "\n",
    "    # shuffle list and select gold standards \n",
    "    random.shuffle(task_list)\n",
    "\n",
    "    with open(os.path.join(data_folder, \"TaskSets/task_list_gold_{}.json\".format(task_type)), 'w+', encoding='utf8') as file:\n",
    "        json.dump(task_list[:golden_standard_quota], file, indent=4, ensure_ascii=False)\n",
    "\n",
    "    # to avoid duplicates in gold and non-gold lists\n",
    "    with open(os.path.join(data_folder, \"TaskSets/task_list_non_gold_{}.json\".format(task_type)), 'w+', encoding='utf8') as file:\n",
    "        json.dump(task_list[golden_standard_quota:], file, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636a7e45",
   "metadata": {},
   "source": [
    "### TODO (!): Before next step: manually set gold labels in task_list_gold.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13884d59",
   "metadata": {},
   "source": [
    "#### Generating tasksets of 7 tasks each (two out of them are gold standards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d372e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling claims: currently no sampling (decide later e.g. using active learning)\n",
    "\n",
    "if update_tasksets and task_type in [\"table_annotation\", \"adjusted_claim_annotation\"]: \n",
    "    with open(os.path.join(data_folder, \"TaskSets/task_list_gold_{}.json\".format(task_type)), \"rb\") as file: \n",
    "        task_list_gold = json.load(file) # load task list of gold standards\n",
    "\n",
    "    with open(os.path.join(data_folder, \"TaskSets/task_list_non_gold_{}.json\".format(task_type)), \"rb\") as file: \n",
    "        task_list_non_gold = json.load(file) # load non gold standard task list\n",
    "\n",
    "    # set number of non-gold tasks to use accord. to how many labelled gold we have\n",
    "    task_sets, counter = generate_taskset_w_ids(task_list_non_gold, task_list_gold)\n",
    "\n",
    "    print(f\"{len(task_sets)} tasksets created out of {len(task_list_gold)} gold tasks and {len(task_list_non_gold)} non-gold tasks.\")\n",
    "\n",
    "    # save tasksets \n",
    "    with open(os.path.join(data_folder, \"TaskSets/tasksets_{}.json\".format(task_type)), 'w+', encoding='utf8') as file:\n",
    "        json.dump(task_sets, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "elif update_tasksets and task_type == \"claim_generation\":\n",
    "    with open(os.path.join(data_folder, \"TaskSets/pre_tasksets_{}.json\".format(task_type)), \"rb\") as file: \n",
    "        task_list_non_gold = json.load(file)\n",
    "    \n",
    "    task_sets, counter = generate_taskset_w_ids_no_gold(task_list_non_gold, n = 5)\n",
    "    print(f\"{len(task_sets)} tasksets created out of {len(task_list_non_gold)} non-gold tasks.\")\n",
    "    \n",
    "    # save tasksets \n",
    "    with open(os.path.join(data_folder, \"TaskSets/tasksets_{}.json\".format(task_type)), 'w+', encoding='utf8') as file:\n",
    "        json.dump(task_sets, file, indent=4, ensure_ascii=False)\n",
    "    \n",
    "else: \n",
    "    print(\"Loading taskset...\")        \n",
    "    with open(os.path.join(data_folder, \"TaskSets/tasksets_{}.json\".format(task_type)), 'rb') as file:\n",
    "        task_sets = json.load(file)\n",
    "        \n",
    "    print(f\"Length of retrieved tasks is {len(task_sets)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46440e96",
   "metadata": {},
   "source": [
    "### 2. Running Crowdsourcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c185626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to preprocess tables for displaying in annotation UI\n",
    "\n",
    "def _remove_attrs(soup):\n",
    "    for tag in soup.findAll(True): \n",
    "        if tag.attrs:\n",
    "            tag.attrs = dict((key,value) for key,value in tag.attrs.items() if key in [\"colspan\", \"align\", \"text\", \"rowspan\"])\n",
    "    \n",
    "    return soup\n",
    "\n",
    "\n",
    "def _remove_tags(soup):\n",
    "    for tag in [\"image\", \"script\", \"caption\", \"noscript\", \"picture\", \"math\", \"figure\", \"name-content\", \"menu\", \"ie:menuitem\", \"iframe\", \"code\", \"gcse:search\", \"img\", \"index\", \"article\", \"map\", \"object\"]: \n",
    "        for elem in soup(tag):\n",
    "                elem.decompose()\n",
    "\n",
    "def _remove_img(soup):\n",
    "    for img in soup(\"img\"):\n",
    "        img.decompose()\n",
    "        \n",
    "\n",
    "def _remove_caption(soup):\n",
    "    for cap in soup(\"caption\"):\n",
    "        cap.decompose()\n",
    "\n",
    "def _remove_script(soup):\n",
    "    for cap in soup(\"script\"):\n",
    "        cap.decompose()\n",
    "\n",
    "        \n",
    "def taskset_tostring(taskSet_list: list): \n",
    "    \"\"\"\n",
    "    Preprocess table representation before sending to UI\n",
    "    \"\"\"\n",
    "    new_list = []\n",
    "    for taskSet in taskSet_list:\n",
    "        html_table = taskSet['table']['html_table']\n",
    "\n",
    "        html_table_bs = BeautifulSoup(html_table)\n",
    "        html_table_bs = _remove_attrs(html_table_bs)\n",
    "        _remove_tags(html_table_bs)\n",
    "\n",
    "        for tag in html_table_bs.findAll([\"table\", \"th\", \"td\"]):\n",
    "            tag['style'] = \"border: 1px solid black;\"\n",
    "\n",
    "#         html_table = str(html_table_bs.body.table).replace(\"\\n\", \"\")\n",
    "#         html_table = str(html_table_bs.body.table).replace(\"\\n\", \"\").replace(\"'\", \"\\'\")\n",
    "\n",
    "        taskSet['table']['html_table'] = html_table\n",
    "    \n",
    "    result_str = str(taskSet_list).replace(\"\\'<table\", \"`<table\").replace(\"table>\\'\", \"table>`\").replace(\"\\xa0\", \" \").replace(\"\\'caption\\': None\", \"\\'caption\\': \\'no caption given\\'\")\n",
    "    result_str = result_str.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "    return result_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a336f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ban workers which are spammers\n",
    "# After pilot round \n",
    "\n",
    "to_ban = False\n",
    "if to_ban:\n",
    "    with open('./config/banlist.json','r') as f:\n",
    "        banlist = json.load(f)\n",
    "    for w in banlist:\n",
    "        try:\n",
    "            print(w)\n",
    "            response = mt.client.create_worker_block(WorkerId=w, Reason='Malicious behaviour.')\n",
    "            assert(response['ResponseMetadata']['HTTPStatusCode'] == 200)\n",
    "        except botocore.exceptions.ClientError as e:\n",
    "            print(f\"Following exception thrown \", e)\n",
    "            continue\n",
    "    print(f\"{len(banlist)} workers banned in total.\")\n",
    "    \n",
    "else: \n",
    "    print(\"No worker banned.\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917a55b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTING GENERAL THINGS, UI, ETC. \n",
    "\n",
    "\"\"\" Create the tasks by populating the HTML templates using the config file \"\"\"\n",
    "\n",
    "with open(config_folder + 'task_config_{}.json'.format(task_type),'r') as f: # load config file with worker qualifications, location, etc. \n",
    "    task_temp = json.load(f)\n",
    "    \n",
    "taskSets_all_lan = {}\n",
    "\n",
    "task_content = copy.deepcopy(task_temp)\n",
    "task_content['language'] = \"en\"\n",
    "\n",
    "TaskAttributes = task_content['task_attributes']\n",
    "\n",
    "with open('./config/' + task_content['instructions_project_text_file'],'r') as f:\n",
    "    task_content['instructions_project_text'] = f.read().replace('\\n',' ')\n",
    "with open('./config/' + task_content['instructions_rules_text_file'],'r') as f:\n",
    "    task_content['instructions_rules_text'] = f.read().replace('\\n',' ')\n",
    "\n",
    "html_layout = open(task_content['html_layout'], 'r').read()\n",
    "\n",
    "# enter instruction texts in the html template \n",
    "html_layout = html_layout.\\\n",
    "    replace('${instructions_project_text}$', task_content['instructions_project_text']).\\\n",
    "    replace('${instructions_rules_text}$', task_content['instructions_rules_text']).\\\n",
    "    replace('${time_thr}$', task_content['time_thr'])\n",
    "\n",
    "with open(data_folder + task_content['tasks'],'r') as f:\n",
    "    taskSets = json.load(f)\n",
    "\n",
    "# If you're only testing, just pick one hit and run it once, with no qualification barriers\n",
    "if not create_hits_in_production:\n",
    "    TaskAttributes.pop('QualificationRequirements')\n",
    "    TaskAttributes['MaxAssignments'] = 1 \n",
    "    random.seed(42)\n",
    "    #taskSets = random.sample(taskSets,1)\n",
    "\n",
    "print('Generated {} tasks with the following configs:'.format(len(taskSets)))\n",
    "pprint(TaskAttributes,indent=1) #verify the properties before running the HITs\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5ff8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE HITS ARE CREATED (=> AMT CALLED) AND SAVED IN MONGODB WITH CORRESP. HIT_ID, later based on these HIT_ID the results are updated\n",
    "\n",
    "\"\"\" Create the batch of HITs \"\"\"\n",
    "\n",
    "results = []\n",
    "batch_id = str(uuid.uuid4())\n",
    "\n",
    "hit_type_id = ''\n",
    "target_assignments = TaskAttributes['MaxAssignments']\n",
    "\n",
    "for taskSet in taskSets[:10]: \n",
    "\n",
    "    TaskAttributes_hit = copy.deepcopy(TaskAttributes) # Adjust based on how many were already done in other batches\n",
    "    TaskAttributes_hit['MaxAssignments'] = target_assignments -\\\n",
    "        sum([hit['hit']['NumberOfAssignmentsCompleted'] for hit in hit_result_collection.find({\n",
    "            'taskSet_id':taskSet['_id'],\n",
    "            'type': task_content['type'],\n",
    "            'language': \"English\"\n",
    "        })])\n",
    "    if TaskAttributes_hit['MaxAssignments'] > 0:\n",
    "        random.seed(None)\n",
    "        language_questions = random.sample(qualification_tests,k=3) # Adjust with table questions\n",
    "        try:\n",
    "#             response = mt.create_hit(html_layout.replace('${references}$', mock_taskSet).\\\n",
    "#                                      replace('${lan_test_questions}$', json.dumps(language_questions)),\n",
    "#                                      **TaskAttributes_hit)\n",
    "            response = mt.create_hit(html_layout.replace('${references}$', taskset_tostring(taskSet['taskSet'])).\\\n",
    "                                     replace('${lan_test_questions}$', json.dumps(language_questions)),\n",
    "                                     **TaskAttributes_hit)\n",
    "            \n",
    "        except Exception as e: \n",
    "            print(f\"Exception occurred, continue with next entry in TaskSets: {e}\")\n",
    "            continue \n",
    "\n",
    "        hit_type_id = response['HIT']['HITTypeId']\n",
    "        result = {\n",
    "            '_id': response['HIT']['HITId'],\n",
    "            'batch_id': batch_id,\n",
    "            'type': task_content['type'],\n",
    "            'references': taskSet['taskSet'],\n",
    "            'language': \"English\",\n",
    "            'taskSet_id':taskSet['_id'],\n",
    "            'hit': response['HIT'],\n",
    "            'timestamp': datetime.now()\n",
    "        }\n",
    "        results.append(result)\n",
    "        try:\n",
    "            hit_result_collection.insert_one(result) # ADD hit with ID returned from AMT to my MongoDB database\n",
    "        except Exception:\n",
    "            print(result)\n",
    "            raise\n",
    "\n",
    "# For you to go to the HITs you just created and test them\n",
    "print('Launched tasks for table fact checking')\n",
    "if not create_hits_in_production:\n",
    "    print('You can view the HITs here:')\n",
    "    print(mt.mturk_environment['preview']+\"?groupId={}\".format(hit_type_id))\n",
    "else:\n",
    "    print('Launched! Good Luck!')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a7ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Update all non-disposed hits in the database with correct results '''\n",
    "\"\"\" Rejected assignments are ignored \"\"\"\n",
    "\n",
    "approve_payment = False # Set to true if automatically approve payment \n",
    "\n",
    "for hit in hit_result_collection.find({'hit.HITStatus': {'$not': {'$eq': 'Disposed'}}, \n",
    "                                       'timestamp': {'$gte': datetime(2020, 6, 30)}}):\n",
    "    \n",
    "    print('Updating',hit['_id'],end='\\r')\n",
    "    try:\n",
    "        hit_result_collection.update_one(\n",
    "            {'_id': hit['_id']},\n",
    "            {\n",
    "                \"$set\": {\n",
    "                    \"hit\": mt.client.get_hit(HITId = hit['_id'])['HIT'],\n",
    "                    'answers': mt.get_hit_answers(hit['_id'], approve=approve_payment)\n",
    "                }\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(e,end='\\n\\n')\n",
    "        continue\n",
    "print('Done'+(' '*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b708f8",
   "metadata": {},
   "source": [
    "#### Delete previously sent HITs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82db9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {'hit.HITStatus': {'$not': {'$eq': 'Disposed'}}}\n",
    "# query['type'] = \"claim_generation\"\n",
    "len(list(hit_result_collection.find(query)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990e8f7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" If you set 'force' to TRUE, it will abort mission and force an expiry in all HITs and then delete them.\n",
    "If you only want to remove the completed ones (make them Disposed so the update routine won't loop through tons of\n",
    "HITs), keep it as FALSE.\"\"\"\n",
    "\n",
    "force = True\n",
    "\n",
    "while True:\n",
    "    ''' Dispose all hits in the database '''\n",
    "    query = {'hit.HITStatus': {'$not': {'$eq': 'Disposed'}}, 'timestamp': {'$gte': datetime(2020, 6, 23)}}\n",
    "#     query[\"type\"] = \"claim_generation\"\n",
    "#     query = {'timestamp': {'$gte': datetime.datetime(2021, 6, 29)}}\n",
    "    \n",
    "    if not force:\n",
    "        query['hit.NumberOfAssignmentsPending'] = 0\n",
    "        query['hit.NumberOfAssignmentsAvailable'] = 0\n",
    "    elif force:\n",
    "        query['hit.NumberOfAssignmentsPending'] = 0\n",
    "#         query['hit.NumberOfAssignmentsCompleted'] = 0\n",
    "    \n",
    "    hit_result_collection_list = list(hit_result_collection.find(query))\n",
    "    print(f\"Length of retrieved HITs \", len(hit_result_collection_list))\n",
    "    \n",
    "    if (not force and len(hit_result_collection_list) == 0) or (force and mt.client.list_hits()['NumResults']==0):\n",
    "        print('Finished')\n",
    "        break\n",
    "        \n",
    "    for hit in hit_result_collection_list:\n",
    "        try:\n",
    "            mt.client.delete_hit(HITId = hit['_id'])\n",
    "            print('Removed',hit['_id'])\n",
    "        except Exception as e:\n",
    "            print(hit['_id'], e)\n",
    "            if force:\n",
    "                print(\"force\")\n",
    "                try:\n",
    "                    mt.client.update_expiration_for_hit(HITId = hit['_id'], ExpireAt=datetime(2018, 4, 10, 7, 22, 15))\n",
    "                    mt.client.get_hit(HITId = hit['_id'])\n",
    "                    mt.client.delete_hit(HITId = hit['_id'])\n",
    "                    print('Removed',hit['_id'])\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                    print(hit['_id'],e)\n",
    "            continue\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7880698",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_list = mt.client.list_hits(MaxResults=100)\n",
    "print(f\"Length of retrieved hits: {len(hit_list['HITs'])}\")\n",
    "force = True\n",
    "\n",
    "for hit in hit_list[\"HITs\"]:\n",
    "    hitid = hit[\"HITId\"]\n",
    "    try:\n",
    "        mt.client.update_expiration_for_hit(HITId = hitid, ExpireAt=datetime(2018, 1, 1))\n",
    "        mt.client.get_hit(HITId = hitid)\n",
    "        mt.client.delete_hit(HITId = hitid)\n",
    "        print('Removed',hitid)\n",
    "    except Exception as e:\n",
    "        print(f\"Following error occured while deleting HIT {hitid}, lets continue: {e}.\")\n",
    "        if force:\n",
    "            try:\n",
    "                mt.client.update_expiration_for_hit(hitid, ExpireAt=datetime(2017, 1, 1))\n",
    "                mt.client.delete_hit(HITId = hitid)\n",
    "                print('Removed', hitid)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "#                 print(hit['_id'],e)\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41baf9fe",
   "metadata": {},
   "source": [
    "#### Delete specific Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e20caea",
   "metadata": {},
   "outputs": [],
   "source": [
    "force = True\n",
    "\n",
    "while True:\n",
    "    ''' Dispose all hits in the database '''\n",
    "    \n",
    "#     if not force:\n",
    "#         query['hit.NumberOfAssignmentsPending'] = 0\n",
    "#         query['hit.NumberOfAssignmentsAvailable'] = 0\n",
    "#     elif force:\n",
    "#         query['hit.NumberOfAssignmentsPending'] = 0\n",
    "    \n",
    "    hit_result_collection_list = [...] # TODO enter here HIT_IDs which should be deleted\n",
    "    \n",
    "#     if (not force and len(hit_result_collection_list) == 0) or (force and mt.client.list_hits()['NumResults']==0):\n",
    "#         print('Finished')\n",
    "#         break\n",
    "        \n",
    "    for hit_id in hit_result_collection_list:\n",
    "        try:\n",
    "            mt.client.update_expiration_for_hit(HITId = hitid, ExpireAt=datetime(2018, 1, 1))\n",
    "            x = mt.client.delete_hit(HITId = hit_id)\n",
    "            print('Removed',hit_id)\n",
    "        except Exception as e:\n",
    "            print(hit_id)\n",
    "            if force:\n",
    "                print(\"force\")\n",
    "                try:\n",
    "                    mt.client.update_expiration_for_hit(HITId = hit_id, ExpireAt=datetime(2017, 1, 1))\n",
    "                    mt.client.delete_hit(HITId = hit_id)\n",
    "                    print('Removed',hit_id)\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                    print(hit_id,e)\n",
    "            continue\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e4b64d",
   "metadata": {},
   "source": [
    "#### Update HITs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cecedc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hitid = '...' # TODO enter HIT_ID you want to update\n",
    "\n",
    "mt.client.update_expiration_for_hit(HITId = hitid, ExpireAt=datetime(2015, 1, 1))\n",
    "\n",
    "# mt.client.update_hit_review_status(HITId = hitid, Revert=True)\n",
    "# mt.client.update_hit_type_of_hit(HITId = hitid, HITTypeId='1623495307575')\n",
    "\n",
    "# mt.get_hit_answers(hitid, approve=True)\n",
    "pprint(mt.client.get_hit(HITId = hitid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89654148",
   "metadata": {},
   "source": [
    "### Preparing html tables for UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d35290",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_folder + \"TaskSets/task_sets_en_table.json\",'r') as f:\n",
    "    task_sets = json.load(f)\n",
    "    \n",
    "subset = []\n",
    "for task_set in task_sets: \n",
    "    for task in task_set['taskSet']: \n",
    "        if (task['table']['header_horizontal']!=[] and any(task['table']['header_horizontal'])) or \\\n",
    "        (task['table']['header_vertical']!=[] and any(task['table']['header_vertical'])): \n",
    "            subset.append(task)\n",
    "            \n",
    "len(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef78ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "from lxml.etree import tostring\n",
    "\n",
    "\n",
    "def del_col_row(table, row_i = None, col_i = None):\n",
    "    \"\"\"remove columns and rows from table\"\"\"\n",
    "\n",
    "    if type(table)==str:\n",
    "        table = html.fragment_fromstring(table)\n",
    "        \n",
    "    # remove column i\n",
    "    if col_i != None:\n",
    "        for row in table.getchildren()[0].iterchildren():\n",
    "            row.remove(row.getchildren()[col_i])\n",
    "        \n",
    "    # remove row i\n",
    "    if row_i != None:\n",
    "        for index, row in zip(range(len(table.getchildren()[0].getchildren())), table.getchildren()[0].iterchildren()):\n",
    "            if index == row_i:\n",
    "                row.getparent().remove(row)\n",
    "    \n",
    "    return table \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee1e7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 1\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_income\"\n",
    "resp = requests.get(url)\n",
    "page = BeautifulSoup(resp.text, 'html.parser')\n",
    "tables = page.findAll(\"table\")\n",
    "\n",
    "table = tables[3]\n",
    "\n",
    "# TODO replace in function del_col_row() e.g. table.getchildren() by table.getchildren()[0].getchildren()\n",
    "# drop columns and rows unnecessary \n",
    "table = html.tostring(del_col_row(str(table), col_i = 3)).decode('utf-8')\n",
    "table = html.tostring(del_col_row(str(table), col_i = 3)).decode('utf-8')\n",
    "table = html.tostring(del_col_row(str(table), col_i = 4)).decode('utf-8')\n",
    "table = html.tostring(del_col_row(str(table), col_i = 4)).decode('utf-8')\n",
    "table = html.tostring(del_col_row(str(table), col_i = 0)).decode('utf-8')\n",
    "\n",
    "for i in range(8):\n",
    "    table = html.tostring(del_col_row(str(table), row_i = 2)).decode('utf-8')\n",
    "for i in range(6):\n",
    "    table = html.tostring(del_col_row(str(table), row_i = 9)).decode('utf-8')\n",
    "for i in range(35):\n",
    "    table = html.tostring(del_col_row(str(table), row_i = 13)).decode('utf-8')\n",
    "    \n",
    "# BeautifulSoup(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e3231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 2\n",
    "\n",
    "url = \"https://www.cdc.gov/flu/about/burden/index.html\"\n",
    "resp = requests.get(url)\n",
    "page = BeautifulSoup(resp.text, 'html.parser')\n",
    "tables = page.findAll(\"table\")\n",
    "\n",
    "table = tables[0]\n",
    "\n",
    "# drop columns and rows unnecessary \n",
    "# table = html.tostring(del_col_row(str(table), col_i = None)).decode('utf-8')\n",
    "\n",
    "for i in range(8):\n",
    "    table = html.tostring(del_col_row(str(table), row_i = 0)).decode('utf-8')\n",
    "    \n",
    "table = html.tostring(del_col_row(str(table), col_i = 2)).decode('utf-8')\n",
    "table = html.tostring(del_col_row(str(table), col_i = 3)).decode('utf-8')\n",
    "table = html.tostring(del_col_row(str(table), col_i = 4)).decode('utf-8')\n",
    "table = html.tostring(del_col_row(str(table), col_i = 5)).decode('utf-8')\n",
    "\n",
    "# Delete second header row.. \n",
    "table = html.fragment_fromstring(table)\n",
    "table.getchildren()[1].remove(table.getchildren()[1].getchildren()[1])\n",
    "# table.getchildren()[1].remove(table.getchildren()[1].getchildren()[0])\n",
    "\n",
    "table = html.tostring(table).decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a6543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 3\n",
    "\n",
    "url = \"https://www.macrotrends.net/countries/AUS/australia/crime-rate-statistics\"\n",
    "resp = requests.get(url)\n",
    "page = BeautifulSoup(resp.text, 'html.parser')\n",
    "tables = page.findAll(\"table\")\n",
    "table = tables[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f26fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 4\n",
    "\n",
    "url = \"https://www.cebm.net/covid-19/global-covid-19-case-fatality-rates\"\n",
    "resp = requests.get(url)\n",
    "page = BeautifulSoup(resp.text, 'html.parser')\n",
    "tables = page.findAll(\"table\")\n",
    "table = tables[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c9d920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 5\n",
    "\n",
    "url = \"https://www.nimh.nih.gov/health/statistics/suicide.shtml\"\n",
    "resp = requests.get(url)\n",
    "page = BeautifulSoup(resp.text, 'html.parser')\n",
    "tables = page.findAll(\"table\")\n",
    "table = tables[0]\n",
    "\n",
    "for i in range(5):\n",
    "    table = html.tostring(del_col_row(str(table), row_i = 5)).decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3addd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table Test\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Demographics_of_the_United_States\"\n",
    "resp = requests.get(url)\n",
    "page = BeautifulSoup(resp.text, 'html.parser')\n",
    "tables = page.findAll(\"table\")\n",
    "table = tables[23]\n",
    "\n",
    "for i in range(5):\n",
    "    table = html.tostring(del_col_row(str(table), row_i = 10)).decode('utf-8')\n",
    "\n",
    "table = html.tostring(del_col_row(str(table), row_i = 0)).decode('utf-8')\n",
    "table = html.tostring(del_col_row(str(table), col_i = 0)).decode('utf-8')\n",
    "\n",
    "table = html.fragment_fromstring(table)\n",
    "table.getchildren()[0].getchildren()[0].remove(table.getchildren()[0].getchildren()[0].getchildren()[4])\n",
    "\n",
    "for row in table.getchildren()[0].iterchildren():\n",
    "    if row.getchildren():\n",
    "#         print(f\"This: {html.tostring(row.getchildren()[0])}\")\n",
    "        row.remove(row.getchildren()[2])\n",
    "        \n",
    "# table = html.tostring(del_col_row(str(table), col_i = 0)).decode('utf-8')\n",
    "\n",
    "table = html.tostring(table).decode('utf-8')\n",
    "BeautifulSoup(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e8df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = subset[100]\n",
    "\n",
    "# if not task['table']['caption']:\n",
    "#     task['table']['caption'] = ''\n",
    "# html_table = task['table']['html_table']\n",
    "\n",
    "html_table_bs = BeautifulSoup(table)\n",
    "# html_table_bs = table\n",
    "html_table_bs = _remove_attrs(html_table_bs)\n",
    "_remove_img(html_table_bs)\n",
    "_remove_caption(html_table_bs)\n",
    "\n",
    "for tag in html_table_bs.findAll([\"table\", \"th\", \"td\"]):\n",
    "    tag['style'] = \"border: 1px solid black;\"\n",
    "\n",
    "html_table = str(html_table_bs).replace(\"\\n\", \"\").replace(\"'\", \"\\'\")\n",
    "# html_table_bs = BeautifulSoup(html_table)\n",
    "\n",
    "print(html_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd91d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load taskset for table task for MOCK HTML page\n",
    "\n",
    "\n",
    "html_table = task_sets[i][\"taskSet\"][entry]['table']['html_table']\n",
    "html_table = html_table.replace(\"\\n\", \"\")\n",
    "html_table = html_table.replace(\"'\", \"\\'\")\n",
    "# html_table = html_table.replace(\"%\", \"\\%\")\n",
    "# html_table = html_table.replace(\"\", \"\\'\")\n",
    "\n",
    "html_table_bs = BeautifulSoup(html_table)\n",
    "html_table_bs = _remove_attrs(html_table_bs)\n",
    "html_table_bs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d85d90",
   "metadata": {},
   "source": [
    "### 3. Updating HITs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b09649",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_table_list = []\n",
    "tags = []\n",
    "\n",
    "for table_list in test_data[\"tables_wikipedia_references\"]:\n",
    "    if table_list and type(table_list)!=float:\n",
    "        for table in table_list: \n",
    "            if table and \"html_table\" in table and type(table[\"html_table\"])==str:\n",
    "                soup = BeautifulSoup(table[\"html_table\"])\n",
    "                tags.extend([tag.name for tag in soup.find_all()])\n",
    "                html_table_list.append(table[\"html_table\"])\n",
    "            \n",
    "len(html_table_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f649e31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = list(set(tags))\n",
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e9c94c",
   "metadata": {},
   "source": [
    "#### Send some taskSets again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8537df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'./data/production/TaskSets/final_table_annotation/tasksets_table_annotation_1.json', \"r\") as file: \n",
    "    taskset_1 = json.load(file)\n",
    "    \n",
    "with open(r'./data/production/TaskSets/final_table_annotation/tasksets_table_annotation_3.json', \"r\") as file: \n",
    "    taskset_3 = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04ba79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_taskSets = []\n",
    "\n",
    "for entry in taskset_1+taskset_3: \n",
    "    for task in entry[\"taskSet\"]:\n",
    "        if task[\"claim_db_id\"] == \"6072bd2a000ca92c09d11fb5\":\n",
    "            task[\"table\"][\"header_horizontal\"] = []\n",
    "            task[\"g_id\"] = 3\n",
    "            relevant_taskSets.append(entry)\n",
    "            \n",
    "        elif task[\"claim_db_id\"] == \"6072bd2d000ca92c09d145b8\":\n",
    "            task[\"g_id\"] = 3\n",
    "            relevant_taskSets.append(entry)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee194de",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'./data/production/TaskSets/final_table_annotation/tasksets_table_annotation_faultyHITs_updated.json', \"w\", encoding=\"utf-8\") as file: \n",
    "    json.dump(relevant_taskSets, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fd135f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
