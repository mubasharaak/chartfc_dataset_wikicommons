{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a09df4f7",
   "metadata": {},
   "source": [
    "# Notebook for crowdsourcing experiments for ChartFC Wikicommons dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5414f1",
   "metadata": {},
   "source": [
    "## Overview \n",
    "This notebook executes the crowdsourcing experiments for the three different tasks \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103ec833",
   "metadata": {},
   "source": [
    "1. <strong>Generate tasksets </strong>\n",
    "\n",
    "\n",
    "2. <strong>Label gold tasks </strong>\n",
    "\n",
    "\n",
    "3. <strong>Sent tasks to Mechanical Turk for annotation</strong> \n",
    "\n",
    "\n",
    "4. <strong>Frequently update task with workers' answers</strong> \n",
    "\n",
    "Set the following constants first:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dd0a52",
   "metadata": {},
   "source": [
    "#### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "406f027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages \n",
    "\n",
    "import bs4 \n",
    "import boto3\n",
    "import botocore\n",
    "import botocore.exceptions\n",
    "import copy\n",
    "import dns\n",
    "import json\n",
    "import certifi\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "import random\n",
    "import requests\n",
    "import uuid\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "from pymongo import MongoClient, InsertOne\n",
    "import pdb\n",
    "\n",
    "from decimal import Decimal\n",
    "from decimal import *\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import xmltodict\n",
    "\n",
    "random.seed(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "c8706307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES \n",
    "\n",
    "PROJECT_PATH = r\"C:\\Users\\k20116188\\PycharmProjects\\chartfc_dataset_wikicommons\"\n",
    "\n",
    "# Folder containing all data files for crowdsourcing\n",
    "DATA_FOLDER = os.path.join(PROJECT_PATH, 'data')\n",
    "\n",
    "# Folder containing all config files for crowdsourcing\n",
    "CONFIG_FOLDER = os.path.join(PROJECT_PATH, 'config')\n",
    "TASK_CONFIG = os.path.join(CONFIG_FOLDER, 'task_config_{}.json') \n",
    "\n",
    "# Set path to .json file with crowdsourcing qualification tests\n",
    "PATH_QUALIFICATION_TESTS = os.path.join(PROJECT_PATH, 'data\\mturk\\qualification_tests.json')\n",
    "\n",
    "# Set task type as one of the following: 'table_annotation', 'claim_generation', 'adjusted_claim_annotation'\n",
    "TASK_TYPE_LIST = [\"chart_filtering\", \"claim_generation\", \"claim_verification\", \"explanation_verification\"]\n",
    "TASK_TYPE = TASK_TYPE_LIST[0] # selected task type\n",
    "\n",
    "# Set to 1 if crowdsourcing tasks in production should be created, else 0 for test\n",
    "CREATE_HITS_IN_PRODUCTION = 1 # !!! DONT CHANGE THIS \n",
    "\n",
    "# Set 1 if current taskSet (if existing) should be updated\n",
    "UPDATE_TASKSETS = 0\n",
    "\n",
    "# Set path to db credentials, used for storing crowdsourcing tasks and results \n",
    "PATH_MONGODB_CREDENTIALS = os.path.join(PROJECT_PATH, 'config/mongodb_credentials.json')\n",
    "\n",
    "# Set path to amazon credentials saved in a .json file\n",
    "PATH_AMAZON_CREDENTIALS = os.path.join(PROJECT_PATH, 'config/amazon_credentials.json')\n",
    "\n",
    "# Set Amazon mturk endpoint used for crowdsourcing experiments\n",
    "MTURK_ENDPOINT = 'https://mturk-requester.us-east-1.amazonaws.com'\n",
    "MTURK_ENDPOINT_SANDBOX = 'https://mturk-requester-sandbox.us-east-1.amazonaws.com'\n",
    "\n",
    "WORKER_BAN_LIST = os.path.join(PROJECT_PATH, 'config/banlist.json')\n",
    "\n",
    "# Path to save created tasks for a task \n",
    "PATH_TASKSETS_FOLDER = os.path.join(DATA_FOLDER, \"mturk\", \"tasksets\")\n",
    "PATH_PRE_TASKSETS = os.path.join(PATH_TASKSETS_FOLDER, \"{}_pre_tasksets.json\")\n",
    "PATH_PRE_TASKSETS_GOLD = os.path.join(PATH_TASKSETS_FOLDER, \"{}_pre_tasksets_gold.json\")\n",
    "PATH_PRE_TASKSETS_NON_GOLD = os.path.join(PATH_TASKSETS_FOLDER, \"{}_pre_tasksets_non_gold.json\")\n",
    "PATH_TASKSETS = os.path.join(PATH_TASKSETS_FOLDER, \"{}_tasksets.json\")\n",
    "\n",
    "# Paths to html files\n",
    "PATH_HTML_TEXT = os.path.join(DATA_FOLDER, \"mturk\", \"html_text\")\n",
    "PATH_HTML_TEMPLATE = os.path.join(PROJECT_PATH, \"code\", \"html_files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "39f6a820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No worker banned.\n"
     ]
    }
   ],
   "source": [
    "# Ban workers which are spammers after pilot round \n",
    "\n",
    "to_ban = False\n",
    "if to_ban:\n",
    "    with open(WORKER_BAN_LIST,'r') as f:\n",
    "        banlist = json.load(f)\n",
    "    for w in banlist:\n",
    "        try:\n",
    "            print(w)\n",
    "            response = mt.client.create_worker_block(WorkerId=w, Reason='Malicious behaviour.')\n",
    "            assert(response['ResponseMetadata']['HTTPStatusCode'] == 200)\n",
    "        except botocore.exceptions.ClientError as e:\n",
    "            print(f\"Following exception thrown \", e)\n",
    "            continue\n",
    "    print(f\"{len(banlist)} workers banned in total.\")\n",
    "    \n",
    "else: \n",
    "    print(\"No worker banned.\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b5cb6a",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "b46cf9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_QUALIFICATION_TESTS,'r') as f:\n",
    "    qualification_tests = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "e0d266e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB connection\n",
    "\n",
    "with open(PATH_MONGODB_CREDENTIALS,'r') as f:\n",
    "    mongodb_credentials = json.load(f)\n",
    "\n",
    "# Connect to Mong\\oDB\n",
    "db_client = pymongo.MongoClient(mongodb_credentials[\"connection_string\"], tlsCAFile=certifi.where()) # connecting to database\n",
    "db = db_client['chartfc']\n",
    "\n",
    "hit_result_collection = db.hit_results if CREATE_HITS_IN_PRODUCTION else db.hit_results_sandbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "11b8179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mturk client\n",
    "\n",
    "class MTurk():\n",
    "\n",
    "    def __init__(self):\n",
    "        with open(PATH_AMAZON_CREDENTIALS)  as f: # get the credentials from AMT \n",
    "            cfg = json.load(f)\n",
    "\n",
    "        self.access_key = cfg['access_key']\n",
    "        self.secret_key = cfg['secret_key']\n",
    "        \n",
    "        self.environments = {\n",
    "            \"production\": {\n",
    "                \"endpoint\": MTURK_ENDPOINT, # set mturk endpoint\n",
    "                \"preview\": \"https://www.mturk.com/mturk/preview\"\n",
    "            },\n",
    "            \"sandbox\": {\n",
    "                \"endpoint\": MTURK_ENDPOINT_SANDBOX, # set mturk endpoint\n",
    "                \"preview\": \"https://workersandbox.mturk.com/mturk/preview\"\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def launch_client(self, production = False):\n",
    "        self.mturk_environment = self.environments[\"production\"] if production else self.environments[\"sandbox\"]\n",
    "        try:\n",
    "            session = boto3.Session(profile_name='mturk')\n",
    "        except botocore.exceptions.ProfileNotFound as e:\n",
    "            session = boto3.Session(\n",
    "                profile_name='mturk',\n",
    "                aws_access_key_id  = self.access_key,\n",
    "                aws_secret_access_key  = self.secret_key\n",
    "            )\n",
    "        self.client = session.client(\n",
    "            service_name= 'mturk',\n",
    "            region_name= 'us-east-1',\n",
    "            endpoint_url= self.mturk_environment['endpoint'],\n",
    "        )\n",
    "        print(self.client.get_account_balance()['AvailableBalance'])\n",
    "\n",
    "    def create_hit(self, html_layout, **TaskAttributes):\n",
    "        QUESTION_XML = \"\"\"<HTMLQuestion xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2011-11-11/HTMLQuestion.xsd\"><HTMLContent><![CDATA[{}]]></HTMLContent><FrameHeight>650</FrameHeight></HTMLQuestion>\"\"\"\n",
    "        question_xml = QUESTION_XML.format(html_layout)\n",
    "        \n",
    "#         print(f\"question_xml: {question_xml}\")\n",
    "        \n",
    "        try:\n",
    "            response = self.client.create_hit(\n",
    "            **TaskAttributes,\n",
    "                Question=question_xml\n",
    "            )\n",
    "        except Exception:\n",
    "            with open('question_debug.xml','w+') as f:\n",
    "                f.write(question_xml)\n",
    "            print(f\"question_xml is {question_xml}.\")\n",
    "            raise\n",
    "\n",
    "        return response\n",
    "    \n",
    "    def get_hit_status(self, HITId):\n",
    "        hit = self.client.get_hit(HITId=HITId)\n",
    "        hit_status = hit['HIT']['HITStatus']\n",
    "        return hit_status\n",
    "\n",
    "    def get_hit_answers(self, HITId, approve=False):\n",
    "\n",
    "        # Get list and number of Assignments that have been completed\n",
    "        hit_assignmentsList = self.client.list_assignments_for_hit(\n",
    "            HITId=HITId,\n",
    "            AssignmentStatuses=['Submitted','Approved']\n",
    "        )\n",
    "\n",
    "        assignments = hit_assignmentsList['Assignments']\n",
    "\n",
    "        # Get details and results of each Assignment and add to answers array\n",
    "        answers = []\n",
    "        for assignment in assignments:\n",
    "            worker_id = assignment['WorkerId']\n",
    "            assignment_id = assignment['AssignmentId']\n",
    "\n",
    "            answer_dict = xmltodict.parse(assignment['Answer'])['QuestionFormAnswers']['Answer']\n",
    "            values = {}\n",
    "            for entry in answer_dict:\n",
    "                try:\n",
    "                    values[entry['QuestionIdentifier']] = json.loads(entry['FreeText'])\n",
    "                except ValueError:\n",
    "                    values[entry['QuestionIdentifier']] = entry['FreeText']\n",
    "                except TypeError:\n",
    "                    values[entry['QuestionIdentifier']] = None\n",
    "\n",
    "            answer = {\n",
    "                'worker_id' : worker_id,\n",
    "                'assignment_id' : assignment_id,\n",
    "                'values' : values,\n",
    "                'HITId' : HITId\n",
    "            }\n",
    "            answers.append(answer)\n",
    "            \n",
    "            if approve:\n",
    "                # Approve or not assignments\n",
    "                if assignment['AssignmentStatus'] == 'Submitted':\n",
    "                    self.client.approve_assignment(\n",
    "                        AssignmentId = assignment_id,\n",
    "                        OverrideRejection = False\n",
    "                    )\n",
    "                    \n",
    "        return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "93dd356f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4971.20\n"
     ]
    }
   ],
   "source": [
    "# Connect to MTurk\n",
    "\n",
    "mt = MTurk()\n",
    "mt.launch_client(production = CREATE_HITS_IN_PRODUCTION)\n",
    "# mt.launch_client(production = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ed9d5a",
   "metadata": {},
   "source": [
    "### Functions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "c0adcb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSingleInstances = 1 # MAX TIMES ANY REFERENCE APPEARS AMONG THE TASK SETS\n",
    "\n",
    "def get_random_task(counter, n, non_gd_tasks):\n",
    "    \"\"\"Returns n random tasks of format (task, index) from list non_gd_tasks\"\"\"\n",
    "    \n",
    "    task_seq = []\n",
    "    p = [max(maxSingleInstances-c,0.0001) for c in counter] # indexes of samples which can be used for task generation \n",
    "    p = [pp/sum(p) for pp in p]\n",
    "    indexes = np.random.choice( # random choice of entries (given some constraints)\n",
    "        a = list(range(len(non_gd_tasks))),\n",
    "        size=n,\n",
    "        replace=False, \n",
    "        p=p # samples used before in other tasks => probability set to 0 so that they are not chosen twice\n",
    "    )        \n",
    "\n",
    "    for i in indexes:\n",
    "        task = non_gd_tasks[i]\n",
    "        task_seq.append((task,i))\n",
    "    \n",
    "    return task_seq\n",
    "\n",
    "\n",
    "def get_random_gd_task(n, gd_tasks):\n",
    "    \"\"\"Returns a sub-list of gd_tasks (ground truth) with n entries\"\"\"\n",
    "    return random.sample(gd_tasks, n)\n",
    "\n",
    "\n",
    "def generate_taskset(counter, non_gd_tasks, gd_tasks, n=(5,2)): # set the number of non-gold labelled tasks (e.g. 5) and gold labelled task (e.g. 2)\n",
    "    '''\n",
    "    counter = a counter which keeps track of how many times each reference was retrieved\n",
    "    n = (x,y) where x = number of non_gd references and y = number of gd references\n",
    "    '''\n",
    "    taskSet = []\n",
    "    \n",
    "    task = get_random_task(counter, n[0], non_gd_tasks) # returns list of (index, sample)\n",
    "    taskSet = [r for (r,i) in task] # pairs reference,index are generated here, so that we can update the counter later\n",
    "    taskSet.extend(get_random_gd_task(n[1], gd_tasks))\n",
    "    \n",
    "    random.shuffle(taskSet) # gold standard should occur anywhere\n",
    "    \n",
    "    return taskSet, [i for (p,i) in task] # indixes returned to update counter\n",
    "\n",
    "\n",
    "def generate_taskset_no_gold(counter, non_gd_tasks, n=5):\n",
    "    \"\"\"\n",
    "    Generates taskset of n (default = 5) tasks and updates counter,\n",
    "    so that a task appears only 'maxSingleInstances'-times in a taskSet\n",
    "    \"\"\"\n",
    "    task_index_set = get_random_task(counter, n, non_gd_tasks) # returns list of (index, sample)\n",
    "    taskSet = [r for (r,i) in task_index_set] # tasks extracted from the pairs of (task, index)\n",
    "    \n",
    "    return taskSet, [i for (p,i) in task_index_set] # indixes returned to update counter\n",
    "\n",
    "\n",
    "def generate_taskset_w_ids(non_gd_tasks, gd_tasks, non_gold_per_taskset, gold_per_taskset) -> list:\n",
    "    \"\"\"\n",
    "    Function to generate TaskSets given gold standards and other samples \n",
    "    \"\"\"\n",
    "    taskSets = []\n",
    "    counter = [0]*len(non_gd_tasks) # keeping track if sample has been used before \n",
    "\n",
    "    while (any([c < maxSingleInstances for c in counter])):\n",
    "        # generate task set with some random samples\n",
    "        taskSet, indexes = generate_taskset(counter, non_gd_tasks, gd_tasks, n=(non_gold_per_taskset, gold_per_taskset)) \n",
    "        taskSetIDd = {\n",
    "            '_id': str(uuid.uuid4()),\n",
    "            'taskSet' : taskSet\n",
    "        }\n",
    "        taskSets.append(taskSetIDd) # add created taskSet with ID to list of taskSets \n",
    "        for i in indexes:\n",
    "            # increase counter for samples added, so that they only appear 'maxSingleInstances'-times in a taskSet\n",
    "            counter[i] = counter[i] + 1 \n",
    "    \n",
    "    return taskSets, counter\n",
    "\n",
    "\n",
    "def generate_taskset_w_ids_no_gold(non_gd_tasks, n = 5) -> list:\n",
    "    \"\"\"\n",
    "    Function to generate TaskSets given samples but without gold labelled samples \n",
    "    n (int): number of non_gold entries per taskSet\n",
    "    \"\"\"\n",
    "    task_set_list = []\n",
    "    counter = [0]*len(non_gd_tasks) # keeping track if sample has been used before \n",
    "\n",
    "    while (any([c < maxSingleInstances for c in counter])): # iterate as long as any sample in non_gd_tasks as not been used\n",
    "        # generate task set with some random samples\n",
    "        task_set, indexes = generate_taskset_no_gold(counter, non_gd_tasks, n) \n",
    "        task_set_w_id = {\n",
    "            '_id': str(uuid.uuid4()),\n",
    "            'taskSet' : task_set\n",
    "        }\n",
    "        \n",
    "        task_set_list.append(task_set_w_id) # add created taskSet with ID to list of taskSets \n",
    "        for i in indexes:\n",
    "            # increase counter for samples added, so that they only appear 'maxSingleInstances'-times in a taskSet\n",
    "            counter[i] = counter[i] + 1 \n",
    "    \n",
    "    return task_set_list, counter\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cee21c4",
   "metadata": {},
   "source": [
    "### 1. Generation of task sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "cacf5681",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of retrieved table: 2316\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>source</th>\n",
       "      <th>description</th>\n",
       "      <th>wikipedia_pages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6390685299c9ed38aa87098d</td>\n",
       "      <td>%25_of_A%26E_Attendees_Seen_within_Four_Hours_...</td>\n",
       "      <td>line_chart</td>\n",
       "      <td>//commons.wikimedia.org/wiki/File:%25_of_A%26E...</td>\n",
       "      <td>https://commons.wikimedia.org/wiki/user:Mattda...</td>\n",
       "      <td>A chart that shows the percentage of A&amp;E atten...</td>\n",
       "      <td>[https://en.wikipedia.org/wiki/Wrightington,_W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6390685299c9ed38aa87098e</td>\n",
       "      <td>-8_Freq._Polygon.JPG</td>\n",
       "      <td>line_chart</td>\n",
       "      <td>//commons.wikimedia.org/wiki/File:-8_Freq._Pol...</td>\n",
       "      <td></td>\n",
       "      <td>class assignment</td>\n",
       "      <td>[https://ca.wikibooks.org/wiki/Viquiprojecte:C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6390685299c9ed38aa87098f</td>\n",
       "      <td>-8_Ogive.JPG</td>\n",
       "      <td>line_chart</td>\n",
       "      <td>//commons.wikimedia.org/wiki/File:-8_Ogive.JPG</td>\n",
       "      <td></td>\n",
       "      <td>class assignment</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  6390685299c9ed38aa87098d   \n",
       "1  6390685299c9ed38aa87098e   \n",
       "2  6390685299c9ed38aa87098f   \n",
       "\n",
       "                                           file_name        type  \\\n",
       "0  %25_of_A%26E_Attendees_Seen_within_Four_Hours_...  line_chart   \n",
       "1                               -8_Freq._Polygon.JPG  line_chart   \n",
       "2                                       -8_Ogive.JPG  line_chart   \n",
       "\n",
       "                                                 url  \\\n",
       "0  //commons.wikimedia.org/wiki/File:%25_of_A%26E...   \n",
       "1  //commons.wikimedia.org/wiki/File:-8_Freq._Pol...   \n",
       "2     //commons.wikimedia.org/wiki/File:-8_Ogive.JPG   \n",
       "\n",
       "                                              source  \\\n",
       "0  https://commons.wikimedia.org/wiki/user:Mattda...   \n",
       "1                                                      \n",
       "2                                                      \n",
       "\n",
       "                                         description  \\\n",
       "0  A chart that shows the percentage of A&E atten...   \n",
       "1                                   class assignment   \n",
       "2                                   class assignment   \n",
       "\n",
       "                                     wikipedia_pages  \n",
       "0  [https://en.wikipedia.org/wiki/Wrightington,_W...  \n",
       "1  [https://ca.wikibooks.org/wiki/Viquiprojecte:C...  \n",
       "2                                                 []  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data from MongoDB database for taskset creation\n",
    "\n",
    "db_table = pd.DataFrame()\n",
    "\n",
    "if TASK_TYPE == \"chart_filtering\": \n",
    "    db_table = db.chart_filtering\n",
    "    cursor = db_table.find({\"type\": {\"$regex\": \"(line_chart|pie_chart|barchart_vertical|barchart_horizontal)\"}})# todo exclude scatterplots\n",
    "    db_table = pd.DataFrame(list(cursor))\n",
    "else:\n",
    "    print(f\"No table for task type {TASK_TYPE}\")\n",
    "    \n",
    "print(f\"Length of retrieved table: {len(db_table)}\")\n",
    "\n",
    "db_table.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "21dd77ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tasks_chart_filtering(df): \n",
    "    \"\"\"\n",
    "    Function to create task set for the task chart filtering \n",
    "    df: database table for which to create task sets\n",
    "    \"\"\"\n",
    "    \n",
    "    # template for chart filtering tasks\n",
    "    task_template = {\n",
    "        \"db_id\": \"\",\n",
    "        \"chart_img\": \"https://chartfc.s3.amazonaws.com/{title}\",\n",
    "        \"caption\": \"\",\n",
    "        \"g_id\": -1 # groundtruth id only -1 if this is a gold sample \n",
    "    }\n",
    "    \n",
    "    task_list = []\n",
    "    # Iterate over data in df and create task sets\n",
    "    for index, row in df.iterrows():\n",
    "        task = copy.deepcopy(task_template)\n",
    "        task[\"db_id\"] = str(row[\"_id\"])\n",
    "        task[\"caption\"] = row[\"description\"]\n",
    "        task[\"chart_img\"] = task[\"chart_img\"].format(title = row[\"file_name\"])\n",
    "        if \"%\" in task[\"chart_img\"]: # img url has \"%\" sign => replace by \"%25\"\n",
    "            task[\"chart_img\"] = task[\"chart_img\"].replace(\"%\", \"%25\")\n",
    "        task_list.append(task)\n",
    "        \n",
    "    print(f\"{len(task_list)} tasks in total created.\\n\")\n",
    "    return task_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "e05dd6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading generated task list from path C:\\Users\\k20116188\\PycharmProjects\\chartfc_dataset_wikicommons\\data\\mturk\\tasksets\\chart_filtering_pre_tasksets.json.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and save tasks for chart filtering \n",
    "CREATE_AND_SAVE_TASKS = 0\n",
    "path = PATH_PRE_TASKSETS.format(TASK_TYPE)\n",
    "\n",
    "if CREATE_AND_SAVE_TASKS: \n",
    "    chart_filtering_tasks = create_tasks_chart_filtering(db_table)\n",
    "    print(f\"Saving generated task list at path {path}.\\n\")\n",
    "\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(chart_filtering_tasks, file, indent=4, ensure_ascii=False)\n",
    "else:\n",
    "    print(f\"Loading generated task list from path {path}.\\n\")\n",
    "    \n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        chart_filtering_tasks = json.load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debb27b2",
   "metadata": {},
   "source": [
    "### Split tasks in gold and non-gold samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "73893a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info: Gold already created and labelled, not creating again\n"
     ]
    }
   ],
   "source": [
    "CREATE_AND_SAVE_GOLD = 0\n",
    "\n",
    "if CREATE_AND_SAVE_GOLD:\n",
    "    golden_standard_quota = 75 # number of gold tasks we want\n",
    "\n",
    "    with open(PATH_PRE_TASKSETS.format(TASK_TYPE), \"rb\") as file: \n",
    "        task_list = json.load(file)\n",
    "\n",
    "    # shuffle list to select gold standards randomly \n",
    "    random.shuffle(task_list)\n",
    "\n",
    "    # save tasks for ground truth labelling \n",
    "    with open(PATH_PRE_TASKSETS_GOLD.format(TASK_TYPE), 'w+', encoding='utf8') as file:\n",
    "        json.dump(task_list[:golden_standard_quota], file, indent=4, ensure_ascii=False)\n",
    "\n",
    "    # save other tasks seperately\n",
    "    with open(PATH_PRE_TASKSETS_NON_GOLD.format(TASK_TYPE), 'w+', encoding='utf8') as file:\n",
    "        json.dump(task_list[golden_standard_quota:], file, indent=4, ensure_ascii=False)\n",
    "else: \n",
    "    print(\"Info: Gold already created and labelled, not creating again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "6bfc0cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # delete all gold annotated from non-gold\n",
    "# with open(PATH_PRE_TASKSETS_NON_GOLD.format(TASK_TYPE), 'r', encoding='utf8') as file:\n",
    "#     non_gold = json.load(file)\n",
    "        \n",
    "# with open(r\"C:\\Users\\k20116188\\PycharmProjects\\chartfc_dataset_wikicommons\\data\\mturk\\tasksets\\chart_filtering_pre_tasksets_gold_annotated.json\", 'r', encoding='utf8') as file:\n",
    "#     gold_annotated = json.load(file)\n",
    "\n",
    "# db_list_gold = [entry[\"db_id\"] for entry in gold_annotated]\n",
    "\n",
    "# non_gold_filtered_entries = []\n",
    "# for entry in non_gold: \n",
    "#     if entry[\"db_id\"] in db_list_gold:\n",
    "#         continue\n",
    "#     non_gold_filtered_entries.append(entry)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "97b28453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(PATH_PRE_TASKSETS_NON_GOLD.format(TASK_TYPE), 'w+', encoding='utf8') as file:\n",
    "#     json.dump(non_gold_filtered_entries, file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636a7e45",
   "metadata": {},
   "source": [
    "### TODO (!): Before next step: manually set gold labels in task_list_gold.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13884d59",
   "metadata": {},
   "source": [
    "#### Generating tasksets of 7 tasks each (two out of them are gold standards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "d372e114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading taskset from path C:\\Users\\k20116188\\PycharmProjects\\chartfc_dataset_wikicommons\\data\\mturk\\tasksets\\chart_filtering_tasksets.json.\n"
     ]
    }
   ],
   "source": [
    "CREATE_AND_SAVE_TASKSETS = 0\n",
    "\n",
    "if CREATE_AND_SAVE_TASKSETS:\n",
    "    # load task list of gold standards\n",
    "    with open(PATH_PRE_TASKSETS_GOLD.format(TASK_TYPE), \"rb\") as file: \n",
    "        task_list_gold = json.load(file) \n",
    "\n",
    "    # load non gold standard task list\n",
    "    with open(PATH_PRE_TASKSETS_NON_GOLD.format(TASK_TYPE), \"rb\") as file: \n",
    "        task_list_non_gold = json.load(file) \n",
    "\n",
    "    # set number of non-gold tasks to use accord. to how many labelled gold we have\n",
    "    task_sets, counter = generate_taskset_w_ids(task_list_non_gold, task_list_gold, non_gold_per_taskset=5, gold_per_taskset=2)\n",
    "\n",
    "    print(f\"{len(task_sets)} tasksets created out of {len(task_list_gold)} gold tasks and {len(task_list_non_gold)} non-gold tasks.\")\n",
    "\n",
    "    # save tasksets \n",
    "    with open(PATH_TASKSETS.format(TASK_TYPE), 'w+', encoding='utf8') as file:\n",
    "        json.dump(task_sets, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "else: \n",
    "    print(f\"Loading taskset from path {PATH_TASKSETS.format(TASK_TYPE)}.\")\n",
    "\n",
    "    with open(PATH_TASKSETS.format(TASK_TYPE), 'r', encoding='utf8') as file:\n",
    "        task_sets = json.load(file)\n",
    "        \n",
    "# NEEDED LATER FOR CLAIM WRITING TASKS \n",
    "\n",
    "# elif update_tasksets and task_type == \"claim_generation\":\n",
    "#     with open(os.path.join(data_folder, \"TaskSets/pre_tasksets_{}.json\".format(task_type)), \"rb\") as file: \n",
    "#         task_list_non_gold = json.load(file)\n",
    "    \n",
    "#     task_sets, counter = generate_taskset_w_ids_no_gold(task_list_non_gold, n = 5)\n",
    "#     print(f\"{len(task_sets)} tasksets created out of {len(task_list_non_gold)} non-gold tasks.\")\n",
    "    \n",
    "#     # save tasksets \n",
    "#     with open(os.path.join(data_folder, \"TaskSets/tasksets_{}.json\".format(task_type)), 'w+', encoding='utf8') as file:\n",
    "#         json.dump(task_sets, file, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46440e96",
   "metadata": {},
   "source": [
    "### 2. Running Crowdsourcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "c185626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to preprocess tables for displaying in annotation UI\n",
    "        \n",
    "def taskset_tostring(taskSet_list: list): \n",
    "    \"\"\"\n",
    "    Covert taskset to string to send to MTurk \n",
    "    \"\"\"    \n",
    "    result_str = str(taskSet_list).replace(\"\\'caption\\': None\", \"\\'caption\\': \\'no caption given\\'\")\n",
    "    result_str = result_str.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "    return result_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "87f7dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading task config to create MTurk tasks\n",
    "\n",
    "\"\"\" Create the tasks by populating the HTML templates using the config file \"\"\"\n",
    "\n",
    "with open(TASK_CONFIG.format(TASK_TYPE),'r') as f: # load config file with worker qualifications, location, etc. \n",
    "    task_temp = json.load(f)\n",
    "    \n",
    "taskSets_all_lan = {}\n",
    "\n",
    "task_content = copy.deepcopy(task_temp)\n",
    "TaskAttributes = task_content['task_attributes']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "917a55b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k20116188\\PycharmProjects\\chartfc_dataset_wikicommons\\data\\mturk\\tasksets\\chart_filtering_tasksets.json\n",
      "Generated 454 tasks with the following configs:\n",
      "{'AssignmentDurationInSeconds': 1800,\n",
      " 'Description': 'This is a pilot study, so useful feedback is rewarded.',\n",
      " 'Keywords': 'Image filtering, fact checking, chart information',\n",
      " 'LifetimeInSeconds': 604800,\n",
      " 'MaxAssignments': 3,\n",
      " 'QualificationRequirements': [{'ActionsGuarded': 'DiscoverPreviewAndAccept',\n",
      "                                'Comparator': 'GreaterThanOrEqualTo',\n",
      "                                'IntegerValues': [95],\n",
      "                                'QualificationTypeId': '000000000000000000L0'},\n",
      "                               {'ActionsGuarded': 'DiscoverPreviewAndAccept',\n",
      "                                'Comparator': 'GreaterThan',\n",
      "                                'IntegerValues': [1000],\n",
      "                                'QualificationTypeId': '00000000000000000040'}],\n",
      " 'Reward': '4',\n",
      " 'Title': 'Filtering chart images'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare HTML page \n",
    "\n",
    "html_layout = open(os.path.join(PATH_HTML_TEMPLATE, task_content['html_layout']), 'r').read()\n",
    "\n",
    "with open(os.path.join(PATH_HTML_TEXT, task_content['instructions_project_text_file']),'r') as f:\n",
    "    task_content['instructions_project_text'] = f.read().replace('\\n',' ')\n",
    "    \n",
    "with open(os.path.join(PATH_HTML_TEXT, task_content['instructions_rules_text_file']),'r') as f:\n",
    "    task_content['instructions_rules_text'] = f.read().replace('\\n',' ')\n",
    "\n",
    "# enter instruction texts in the html template \n",
    "html_layout = html_layout.\\\n",
    "    replace('${instructions_project_text}$', task_content['instructions_project_text']).\\\n",
    "    replace('${instructions_rules_text}$', task_content['instructions_rules_text']).\\\n",
    "    replace('${time_thr}$', task_content['time_thr'])\n",
    "\n",
    "print(os.path.join(PATH_TASKSETS_FOLDER, task_content['tasks']))\n",
    "with open(os.path.join(PATH_TASKSETS_FOLDER, task_content['tasks']),'r', encoding='utf8') as f:\n",
    "    taskSets = json.load(f)\n",
    "\n",
    "# If you're only testing, just pick one hit and run it once, with no qualification barriers\n",
    "if not CREATE_HITS_IN_PRODUCTION:\n",
    "    TaskAttributes.pop('QualificationRequirements')\n",
    "    TaskAttributes['MaxAssignments'] = 1 \n",
    "    random.seed(42)\n",
    "    taskSets = random.sample(taskSets,1)\n",
    "else:\n",
    "    pass\n",
    "#     random.seed(42)\n",
    "#     taskSets = random.sample(taskSets,1)  \n",
    "\n",
    "print('Generated {} tasks with the following configs:'.format(len(taskSets)))\n",
    "pprint(TaskAttributes, indent=1) #verify the properties before running the HITs\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "f3e7a58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract taskSets not already in db table \"hit_results\"\n",
    "query = {'hit.HITStatus': {'$not': {'$eq': 'Disposed'}}}\n",
    "projection = {'taskSet_id': 1}\n",
    "hit_result_collection_list = list(hit_result_collection.find(query, projection))\n",
    "hit_result_collection_list_ids = [entry['taskSet_id'] for entry in hit_result_collection_list]\n",
    "\n",
    "taskSets_filtered = [entry for entry in taskSets if entry['_id'] not in hit_result_collection_list_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeb5bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(taskSets_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "abc37be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launched tasks for table fact checking\n",
      "Launched! Good Luck!\n"
     ]
    }
   ],
   "source": [
    "# Creating hits and saving in MongoDb with HIT_ID\n",
    "# later based on the HIT_ID the results are updated\n",
    "\n",
    "\"\"\" Create the batch of HITs \"\"\"\n",
    "\n",
    "results = []\n",
    "batch_id = str(uuid.uuid4())\n",
    "hit_type_id = ''\n",
    "target_assignments = TaskAttributes['MaxAssignments']\n",
    "\n",
    "for taskSet in taskSets_filtered[:X]: \n",
    "    TaskAttributes_hit = copy.deepcopy(TaskAttributes) # Adjust based on how many were already done in other batches\n",
    "    TaskAttributes_hit['MaxAssignments'] = target_assignments -\\\n",
    "        sum([hit['hit']['NumberOfAssignmentsCompleted'] for hit in hit_result_collection.find({\n",
    "            'taskSet_id':taskSet['_id'],\n",
    "            'type': task_content['type']\n",
    "        })])\n",
    "    if TaskAttributes_hit['MaxAssignments'] > 0:\n",
    "        random.seed(None)\n",
    "        qualification_questions = random.sample(qualification_tests, k=3) # Adjust with table questions\n",
    "        try:\n",
    "            html_layout_replaced = html_layout.replace('${references}$', taskset_tostring(taskSet['taskSet'])).\\\n",
    "                                    replace('${qualification_questions}$', json.dumps(qualification_questions))\n",
    "                        \n",
    "            response = mt.create_hit(html_layout_replaced, **TaskAttributes_hit)\n",
    "            \n",
    "        except Exception as e: \n",
    "            print(f\"Exception occurred, continue with next entry in TaskSets: {e}\\n\")\n",
    "            pdb.set_trace()            \n",
    "            raise\n",
    "            continue \n",
    "\n",
    "        hit_type_id = response['HIT']['HITTypeId']\n",
    "        result = {\n",
    "            '_id': response['HIT']['HITId'],\n",
    "            'batch_id': batch_id,\n",
    "            'type': task_content['type'],\n",
    "            'references': taskSet['taskSet'],\n",
    "            'taskSet_id':taskSet['_id'],\n",
    "            'hit': response['HIT'],\n",
    "            'timestamp': datetime.now()\n",
    "        }\n",
    "        results.append(result)\n",
    "        try:\n",
    "            hit_result_collection.insert_one(result) # ADD hit with ID returned from AMT to my MongoDB database\n",
    "        except Exception:\n",
    "            print(result)\n",
    "#             raise\n",
    "\n",
    "# For you to go to the HITs you just created and test them\n",
    "print('Launched tasks for table fact checking')\n",
    "if not CREATE_HITS_IN_PRODUCTION:\n",
    "    print('You can view the HITs here:')\n",
    "    print(mt.mturk_environment['preview']+\"?groupId={}\".format(hit_type_id))\n",
    "else:\n",
    "    print('Launched! Good Luck!')\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a953f8",
   "metadata": {},
   "source": [
    "### Find optimal number of gold-labelled tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "66c0dd03",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k20116188\\AppData\\Local\\Temp\\ipykernel_39368\\3866147424.py:2: DeprecationWarning: Using factorial() with floats is deprecated\n",
      "  return Decimal(math.factorial(x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20c6b9a18b0>]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fac(x):\n",
    "    return Decimal(math.factorial(x))\n",
    "x = 15\n",
    "ys = list(range(20,100))\n",
    "zs = [y*(y-1)/2 for y in ys]\n",
    "ps = [fac(z)/(Decimal(z**x)*fac(z-x)) for z in zs]\n",
    "\n",
    "plt.plot(ys,ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2c72bb",
   "metadata": {},
   "source": [
    "### Update DB collection \"hit_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "84f52474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done                                                                                                    \n"
     ]
    }
   ],
   "source": [
    "''' Update all non-disposed hits in the database with data collected from MTurk '''\n",
    "\"\"\" Rejected assignments are ignored \"\"\"\n",
    "\n",
    "APPROVE_PAYMENT = False # Set to true if automatically approve payment \n",
    "\n",
    "for hit in hit_result_collection.find({'hit.HITStatus': {'$not': {'$eq': 'Disposed'}}}):\n",
    "    # iterating over hits previously sent to MTurk\n",
    "    print('Updating',hit['_id'],end='\\r')\n",
    "\n",
    "    try:\n",
    "        hit_result_collection.update_one(\n",
    "            {'_id': hit['_id']},\n",
    "            {\n",
    "                \"$set\": {\n",
    "                    \"hit\": mt.client.get_hit(HITId = hit['_id'])['HIT'],\n",
    "                    'answers': mt.get_hit_answers(hit['_id'], approve=APPROVE_PAYMENT)\n",
    "                }\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Following exception occurred for hit {hit['_id']}: {e}\",end='\\n\\n')\n",
    "        continue\n",
    "print('Done'+(' '*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24dc4cc",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3657bf",
   "metadata": {},
   "source": [
    "## TODO go over this code later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b708f8",
   "metadata": {},
   "source": [
    "#### Delete previously sent HITs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e82db9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = {'hit.HITStatus': {'$not': {'$eq': 'Disposed'}}}\n",
    "# query['type'] = \"claim_generation\"\n",
    "len(list(hit_result_collection.find(query)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "990e8f7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of retrieved HITs  0\n"
     ]
    }
   ],
   "source": [
    "\"\"\" If you set 'force' to TRUE, it will abort mission and force an expiry in all HITs and then delete them.\n",
    "If you only want to remove the completed ones (make them Disposed so the update routine won't loop through tons of\n",
    "HITs), keep it as FALSE.\"\"\"\n",
    "\n",
    "force = True\n",
    "\n",
    "while True:\n",
    "    ''' Dispose all hits in the database '''\n",
    "    query = {'hit.HITStatus': {'$not': {'$eq': 'Disposed'}}}\n",
    "#     query[\"type\"] = \"claim_generation\"\n",
    "#     query = {'timestamp': {'$gte': datetime.datetime(2021, 6, 29)}}\n",
    "    \n",
    "    if not force:\n",
    "        query['hit.NumberOfAssignmentsPending'] = 0\n",
    "        query['hit.NumberOfAssignmentsAvailable'] = 0\n",
    "    elif force:\n",
    "        query['hit.NumberOfAssignmentsPending'] = 0\n",
    "        query['hit.NumberOfAssignmentsCompleted'] = 0\n",
    "    \n",
    "    hit_result_collection_list = list(hit_result_collection.find(query))\n",
    "    print(f\"Length of retrieved HITs \", len(hit_result_collection_list))\n",
    "    \n",
    "    if (not force and len(hit_result_collection_list) == 0) or (force and mt.client.list_hits()['NumResults']==0):\n",
    "        print('Finished')\n",
    "        break\n",
    "        \n",
    "    for hit in hit_result_collection_list:\n",
    "        try:\n",
    "            mt.client.delete_hit(HITId = hit['_id'])\n",
    "            print('Removed',hit['_id'])\n",
    "        except Exception as e:\n",
    "            print(hit['_id'], e)\n",
    "            \n",
    "            if force:\n",
    "                print(\"force\")\n",
    "                try:\n",
    "                    mt.client.update_expiration_for_hit(HITId = hit['_id'], ExpireAt=datetime(2018, 4, 10, 7, 22, 15))\n",
    "                    mt.client.get_hit(HITId = hit['_id'])\n",
    "                    mt.client.delete_hit(HITId = hit['_id'])\n",
    "                    print('Removed',hit['_id'])\n",
    "                except Exception as e:\n",
    "#                     pass\n",
    "#                     print(hit['_id'],e)\n",
    "                    \n",
    "#                     if status == 'Reviewable':\n",
    "                    assignments = mt.client.list_assignments_for_hit(HITId=hit['_id'], AssignmentStatuses=['Reviewable'])\n",
    "                    if assignments['NumResults'] > 0:\n",
    "                        for assign in assignments['Assignments']:\n",
    "                            mt.client.approve_assignment(AssignmentId=assign['AssignmentId'])\n",
    "                    try:\n",
    "                        mt.client.delete_hit(HITId=hit['_id'])\n",
    "                    except:\n",
    "                        pass\n",
    "                        print(hit['_id'],e)\n",
    "            continue\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a7880698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of retrieved hits: 4\n",
      "Following error occured while deleting HIT 37OPIVELV11LUN7VR1893PLADE5HA0, lets continue: An error occurred (RequestError) when calling the DeleteHIT operation: This HIT is currently in the state 'Unassignable'.  This operation can be called with a status of: Reviewing, Reviewable (1676311651593).\n",
      "Following error occured while deleting HIT 3ZTE0JGGDLQJFJQGFSZQTT8ZP34OCX, lets continue: An error occurred (RequestError) when calling the DeleteHIT operation: This HIT is currently in the state 'Unassignable'.  This operation can be called with a status of: Reviewing, Reviewable (1676311653119).\n",
      "Following error occured while deleting HIT 33NOQL7TAVXT2KEA0PU275JKJGM8ZD, lets continue: An error occurred (RequestError) when calling the DeleteHIT operation: This HIT is currently in the state 'Unassignable'.  This operation can be called with a status of: Reviewing, Reviewable (1676311654692).\n",
      "Following error occured while deleting HIT 3B286OTITLFHLT2LF1BUF21PQ69JA7, lets continue: An error occurred (RequestError) when calling the DeleteHIT operation: This HIT is currently in the state 'Unassignable'.  This operation can be called with a status of: Reviewing, Reviewable (1676311656239).\n"
     ]
    }
   ],
   "source": [
    "hit_list = mt.client.list_hits(MaxResults=100)\n",
    "print(f\"Length of retrieved hits: {len(hit_list['HITs'])}\")\n",
    "force = True\n",
    "\n",
    "for hit in hit_list[\"HITs\"]:\n",
    "    hitid = hit[\"HITId\"]\n",
    "    try:\n",
    "        mt.client.update_expiration_for_hit(HITId = hitid, ExpireAt=datetime(2018, 1, 1))\n",
    "        mt.client.get_hit(HITId = hitid)\n",
    "        mt.client.delete_hit(HITId = hitid)\n",
    "        print('Removed',hitid)\n",
    "    except Exception as e:\n",
    "        print(f\"Following error occured while deleting HIT {hitid}, lets continue: {e}.\")\n",
    "        if force:\n",
    "            try:\n",
    "                mt.client.update_expiration_for_hit(hitid, ExpireAt=datetime(2017, 1, 1))\n",
    "                mt.client.delete_hit(HITId = hitid)\n",
    "                print('Removed', hitid)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "#                 print(hit['_id'],e)\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41baf9fe",
   "metadata": {},
   "source": [
    "#### Delete specific Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e20caea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ellipsis\n",
      "force\n",
      "Ellipsis Parameter validation failed:\n",
      "Invalid type for parameter HITId, value: Ellipsis, type: <class 'ellipsis'>, valid types: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "force = True\n",
    "\n",
    "while True:\n",
    "    ''' Dispose all hits in the database '''\n",
    "    \n",
    "    if not force:\n",
    "        query['hit.NumberOfAssignmentsPending'] = 0\n",
    "        query['hit.NumberOfAssignmentsAvailable'] = 0\n",
    "    elif force:\n",
    "        query['hit.NumberOfAssignmentsPending'] = 0\n",
    "    \n",
    "    hit_result_collection_list = [...] # TODO enter here HIT_IDs which should be deleted\n",
    "    \n",
    "    if (not force and len(hit_result_collection_list) == 0) or (force and mt.client.list_hits()['NumResults']==0):\n",
    "        print('Finished')\n",
    "        break\n",
    "        \n",
    "    for hit_id in hit_result_collection_list:\n",
    "        try:\n",
    "            mt.client.update_expiration_for_hit(HITId = hitid, ExpireAt=datetime(2018, 1, 1))\n",
    "            x = mt.client.delete_hit(HITId = hit_id)\n",
    "            print('Removed',hit_id)\n",
    "        except Exception as e:\n",
    "            print(hit_id)\n",
    "            if force:\n",
    "                print(\"force\")\n",
    "                try:\n",
    "                    mt.client.update_expiration_for_hit(HITId = hit_id, ExpireAt=datetime(2017, 1, 1))\n",
    "                    mt.client.delete_hit(HITId = hit_id)\n",
    "                    print('Removed',hit_id)\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                    print(hit_id,e)\n",
    "            continue\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e4b64d",
   "metadata": {},
   "source": [
    "#### Update HITs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cecedc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hitid = '...' # TODO enter HIT_ID you want to update\n",
    "\n",
    "mt.client.update_expiration_for_hit(HITId = hitid, ExpireAt=datetime(2015, 1, 1))\n",
    "\n",
    "# mt.client.update_hit_review_status(HITId = hitid, Revert=True)\n",
    "# mt.client.update_hit_type_of_hit(HITId = hitid, HITTypeId='1623495307575')\n",
    "\n",
    "# mt.get_hit_answers(hitid, approve=True)\n",
    "pprint(mt.client.get_hit(HITId = hitid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89654148",
   "metadata": {},
   "source": [
    "### Preparing html tables for UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d35290",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_folder + \"TaskSets/task_sets_en_table.json\",'r') as f:\n",
    "    task_sets = json.load(f)\n",
    "    \n",
    "subset = []\n",
    "for task_set in task_sets: \n",
    "    for task in task_set['taskSet']: \n",
    "        if (task['table']['header_horizontal']!=[] and any(task['table']['header_horizontal'])) or \\\n",
    "        (task['table']['header_vertical']!=[] and any(task['table']['header_vertical'])): \n",
    "            subset.append(task)\n",
    "            \n",
    "len(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef78ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "from lxml.etree import tostring\n",
    "\n",
    "\n",
    "def del_col_row(table, row_i = None, col_i = None):\n",
    "    \"\"\"remove columns and rows from table\"\"\"\n",
    "\n",
    "    if type(table)==str:\n",
    "        table = html.fragment_fromstring(table)\n",
    "        \n",
    "    # remove column i\n",
    "    if col_i != None:\n",
    "        for row in table.getchildren()[0].iterchildren():\n",
    "            row.remove(row.getchildren()[col_i])\n",
    "        \n",
    "    # remove row i\n",
    "    if row_i != None:\n",
    "        for index, row in zip(range(len(table.getchildren()[0].getchildren())), table.getchildren()[0].iterchildren()):\n",
    "            if index == row_i:\n",
    "                row.getparent().remove(row)\n",
    "    \n",
    "    return table \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee1e7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 1\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_income\"\n",
    "resp = requests.get(url)\n",
    "page = BeautifulSoup(resp.text, 'html.parser')\n",
    "tables = page.findAll(\"table\")\n",
    "\n",
    "table = tables[3]\n",
    "\n",
    "# TODO replace in function del_col_row() e.g. table.getchildren() by table.getchildren()[0].getchildren()\n",
    "# drop columns and rows unnecessary \n",
    "table = html.tostring(del_col_row(str(table), col_i = 3)).decode('utf-8')\n",
    "table = html.tostring(del_col_row(str(table), col_i = 3)).decode('utf-8')\n",
    "table = html.tostring(del_col_row(str(table), col_i = 4)).decode('utf-8')\n",
    "table = html.tostring(del_col_row(str(table), col_i = 4)).decode('utf-8')\n",
    "table = html.tostring(del_col_row(str(table), col_i = 0)).decode('utf-8')\n",
    "\n",
    "for i in range(8):\n",
    "    table = html.tostring(del_col_row(str(table), row_i = 2)).decode('utf-8')\n",
    "for i in range(6):\n",
    "    table = html.tostring(del_col_row(str(table), row_i = 9)).decode('utf-8')\n",
    "for i in range(35):\n",
    "    table = html.tostring(del_col_row(str(table), row_i = 13)).decode('utf-8')\n",
    "    \n",
    "# BeautifulSoup(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e3231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 2\n",
    "\n",
    "url = \"https://www.cdc.gov/flu/about/burden/index.html\"\n",
    "resp = requests.get(url)\n",
    "page = BeautifulSoup(resp.text, 'html.parser')\n",
    "tables = page.findAll(\"table\")\n",
    "\n",
    "table = tables[0]\n",
    "\n",
    "# drop columns and rows unnecessary \n",
    "# table = html.tostring(del_col_row(str(table), col_i = None)).decode('utf-8')\n",
    "\n",
    "for i in range(8):\n",
    "    table = html.tostring(del_col_row(str(table), row_i = 0)).decode('utf-8')\n",
    "    \n",
    "table = html.tostring(del_col_row(str(table), col_i = 2)).decode('utf-8')\n",
    "table = html.tostring(del_col_row(str(table), col_i = 3)).decode('utf-8')\n",
    "table = html.tostring(del_col_row(str(table), col_i = 4)).decode('utf-8')\n",
    "table = html.tostring(del_col_row(str(table), col_i = 5)).decode('utf-8')\n",
    "\n",
    "# Delete second header row.. \n",
    "table = html.fragment_fromstring(table)\n",
    "table.getchildren()[1].remove(table.getchildren()[1].getchildren()[1])\n",
    "# table.getchildren()[1].remove(table.getchildren()[1].getchildren()[0])\n",
    "\n",
    "table = html.tostring(table).decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a6543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 3\n",
    "\n",
    "url = \"https://www.macrotrends.net/countries/AUS/australia/crime-rate-statistics\"\n",
    "resp = requests.get(url)\n",
    "page = BeautifulSoup(resp.text, 'html.parser')\n",
    "tables = page.findAll(\"table\")\n",
    "table = tables[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f26fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 4\n",
    "\n",
    "url = \"https://www.cebm.net/covid-19/global-covid-19-case-fatality-rates\"\n",
    "resp = requests.get(url)\n",
    "page = BeautifulSoup(resp.text, 'html.parser')\n",
    "tables = page.findAll(\"table\")\n",
    "table = tables[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c9d920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 5\n",
    "\n",
    "url = \"https://www.nimh.nih.gov/health/statistics/suicide.shtml\"\n",
    "resp = requests.get(url)\n",
    "page = BeautifulSoup(resp.text, 'html.parser')\n",
    "tables = page.findAll(\"table\")\n",
    "table = tables[0]\n",
    "\n",
    "for i in range(5):\n",
    "    table = html.tostring(del_col_row(str(table), row_i = 5)).decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3addd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table Test\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Demographics_of_the_United_States\"\n",
    "resp = requests.get(url)\n",
    "page = BeautifulSoup(resp.text, 'html.parser')\n",
    "tables = page.findAll(\"table\")\n",
    "table = tables[23]\n",
    "\n",
    "for i in range(5):\n",
    "    table = html.tostring(del_col_row(str(table), row_i = 10)).decode('utf-8')\n",
    "\n",
    "table = html.tostring(del_col_row(str(table), row_i = 0)).decode('utf-8')\n",
    "table = html.tostring(del_col_row(str(table), col_i = 0)).decode('utf-8')\n",
    "\n",
    "table = html.fragment_fromstring(table)\n",
    "table.getchildren()[0].getchildren()[0].remove(table.getchildren()[0].getchildren()[0].getchildren()[4])\n",
    "\n",
    "for row in table.getchildren()[0].iterchildren():\n",
    "    if row.getchildren():\n",
    "#         print(f\"This: {html.tostring(row.getchildren()[0])}\")\n",
    "        row.remove(row.getchildren()[2])\n",
    "        \n",
    "# table = html.tostring(del_col_row(str(table), col_i = 0)).decode('utf-8')\n",
    "\n",
    "table = html.tostring(table).decode('utf-8')\n",
    "BeautifulSoup(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e8df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = subset[100]\n",
    "\n",
    "# if not task['table']['caption']:\n",
    "#     task['table']['caption'] = ''\n",
    "# html_table = task['table']['html_table']\n",
    "\n",
    "html_table_bs = BeautifulSoup(table)\n",
    "# html_table_bs = table\n",
    "html_table_bs = _remove_attrs(html_table_bs)\n",
    "_remove_img(html_table_bs)\n",
    "_remove_caption(html_table_bs)\n",
    "\n",
    "for tag in html_table_bs.findAll([\"table\", \"th\", \"td\"]):\n",
    "    tag['style'] = \"border: 1px solid black;\"\n",
    "\n",
    "html_table = str(html_table_bs).replace(\"\\n\", \"\").replace(\"'\", \"\\'\")\n",
    "# html_table_bs = BeautifulSoup(html_table)\n",
    "\n",
    "print(html_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd91d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load taskset for table task for MOCK HTML page\n",
    "\n",
    "\n",
    "html_table = task_sets[i][\"taskSet\"][entry]['table']['html_table']\n",
    "html_table = html_table.replace(\"\\n\", \"\")\n",
    "html_table = html_table.replace(\"'\", \"\\'\")\n",
    "# html_table = html_table.replace(\"%\", \"\\%\")\n",
    "# html_table = html_table.replace(\"\", \"\\'\")\n",
    "\n",
    "html_table_bs = BeautifulSoup(html_table)\n",
    "html_table_bs = _remove_attrs(html_table_bs)\n",
    "html_table_bs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d85d90",
   "metadata": {},
   "source": [
    "### 3. Updating HITs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b09649",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_table_list = []\n",
    "tags = []\n",
    "\n",
    "for table_list in test_data[\"tables_wikipedia_references\"]:\n",
    "    if table_list and type(table_list)!=float:\n",
    "        for table in table_list: \n",
    "            if table and \"html_table\" in table and type(table[\"html_table\"])==str:\n",
    "                soup = BeautifulSoup(table[\"html_table\"])\n",
    "                tags.extend([tag.name for tag in soup.find_all()])\n",
    "                html_table_list.append(table[\"html_table\"])\n",
    "            \n",
    "len(html_table_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f649e31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = list(set(tags))\n",
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e9c94c",
   "metadata": {},
   "source": [
    "#### Send some taskSets again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8537df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'./data/production/TaskSets/final_table_annotation/tasksets_table_annotation_1.json', \"r\") as file: \n",
    "    taskset_1 = json.load(file)\n",
    "    \n",
    "with open(r'./data/production/TaskSets/final_table_annotation/tasksets_table_annotation_3.json', \"r\") as file: \n",
    "    taskset_3 = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04ba79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_taskSets = []\n",
    "\n",
    "for entry in taskset_1+taskset_3: \n",
    "    for task in entry[\"taskSet\"]:\n",
    "        if task[\"claim_db_id\"] == \"6072bd2a000ca92c09d11fb5\":\n",
    "            task[\"table\"][\"header_horizontal\"] = []\n",
    "            task[\"g_id\"] = 3\n",
    "            relevant_taskSets.append(entry)\n",
    "            \n",
    "        elif task[\"claim_db_id\"] == \"6072bd2d000ca92c09d145b8\":\n",
    "            task[\"g_id\"] = 3\n",
    "            relevant_taskSets.append(entry)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee194de",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'./data/production/TaskSets/final_table_annotation/tasksets_table_annotation_faultyHITs_updated.json', \"w\", encoding=\"utf-8\") as file: \n",
    "    json.dump(relevant_taskSets, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fd135f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
