{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages \n",
    "\n",
    "import collections\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "import seaborn as sns\n",
    "import uuid\n",
    "\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dba37ea",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b68649",
   "metadata": {},
   "source": [
    "1. <strong>Load annotations for a task </strong>\n",
    "\n",
    "\n",
    "2. <strong>Calculate stats related to this task, e.g. number of workers, time for annotation, etc. </strong>\n",
    "\n",
    "\n",
    "3. <strong>Apply majority voting and update database </strong> \n",
    "\n",
    "Set the following variables first:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the task to be postprocessed: \"table_relevance\", \"claim_adjustment\", \"verification\"\n",
    "task = \"\"\n",
    "\n",
    "# Load file with annotations into pandas.DataFrame OR if annotations saved in DB, create client and load data, example below \n",
    "df = pd.DataFrame()\n",
    "\n",
    "# List of banned workers, if any (.json file)\n",
    "path_banned_workers = ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load annotation data from MongoDB \n",
    "\n",
    "with open(path_database_config,'r') as f:\n",
    "    mongodb_credentials = json.load(f)\n",
    "\n",
    "db_client = pymongo.MongoClient(mongodb_credentials[\"connection_string\"])\n",
    "db = db_client[database_name]\n",
    "\n",
    "hit_result_collection = db.hit_results\n",
    "cursor = hit_result_collection.find({\"type\": task})\n",
    "df = pd.DataFrame(list(cursor))\n",
    "\n",
    "print(f\"Number of samples in 'hit_result_collection' is {len(df_unfiltered)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load list of banned workers to exclude them\n",
    "with open(path_banned_workers,'r') as f:\n",
    "    banlist = json.load(f)\n",
    "\n",
    "# load list of rejected assignments to exclude them (if any exist)\n",
    "rejected_assignments = pd.read_excel(\"filled_answer_df.xlsx\")\n",
    "rejected_assignments = list(rejected_assignments[rejected_assignments[\"reject\"]==1].assignment_id)\n",
    "\n",
    "print(f\"Number of banned workers is {len(banlist)}.\")\n",
    "print(f\"Number of rejected assignments is {len(rejected_assignments)}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(df.columns)\n",
    "cols.remove(\"language\")\n",
    "cols.remove(\"type\")\n",
    "cols.remove(\"timestamp\")\n",
    "cols.remove(\"answers\")\n",
    "cols.extend(['worker_id', 'outputs', 'times', 'events', 'feedback'])\n",
    "\n",
    "annotations_df = pd.DataFrame(columns = cols)\n",
    "counter_skip = 0\n",
    "index = 0\n",
    "for i, row in df.iterrows(): \n",
    "    if task != \"claim_generation\" and (type(row[\"answers\"])!=list or len(row[\"answers\"]) < 3): # we only consider df entries with completed assignments 3/3\n",
    "        counter_skip += 1\n",
    "        continue \n",
    "    \n",
    "    for worker_answer in row[\"answers\"]:\n",
    "        if worker_answer[\"worker_id\"] in banlist or worker_answer[\"assignment_id\"] in rejected_assignments:\n",
    "            print(\"Skipped because worker is banned or assignment has been rejected.\")\n",
    "            counter_skip += 1\n",
    "            continue\n",
    "        \n",
    "        row[\"worker_id\"] = worker_answer[\"worker_id\"]\n",
    "        annotations_df.at[index, \"_id\"] = row[\"_id\"]\n",
    "        annotations_df.at[index, \"batch_id\"] = row[\"batch_id\"]\n",
    "        annotations_df.at[index, \"references\"] = row[\"references\"]\n",
    "        annotations_df.at[index, \"taskSet_id\"] = row[\"taskSet_id\"]\n",
    "        annotations_df.at[index, \"hit\"] = row[\"hit\"]\n",
    "        \n",
    "        annotations_df.at[index, \"worker_id\"] = worker_answer[\"worker_id\"]\n",
    "        annotations_df.at[index, \"outputs\"] = worker_answer[\"values\"][\"outputs\"]\n",
    "        annotations_df.at[index, \"times\"] = worker_answer[\"values\"][\"times\"]\n",
    "        annotations_df.at[index, \"events\"] = worker_answer[\"values\"][\"events\"]\n",
    "        annotations_df.at[index, \"feedback\"] = worker_answer[\"values\"][\"feedback\"]\n",
    "        index += 1\n",
    "\n",
    "print(len(annotations_df))\n",
    "counter_skip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | worker | claim id | label |\n",
    "\n",
    "if task in [\"table_annotation\", \"adjusted_claim_annotation\"]:\n",
    "    output_df = pd.DataFrame(columns=[\"HIT_id\", \"batch_id\", \"taskSet_id\", \"worker_id\", \"claim_id\", \"claim\", \"table\",\n",
    "                                      \"label\", \"header\", \"events\"])\n",
    "\n",
    "    index = 0\n",
    "    for i, row in annotations_df.iterrows():\n",
    "        for j in range(len(row[\"references\"])):\n",
    "            if row[\"references\"][j][\"g_id\"]!=-1:\n",
    "                continue\n",
    "\n",
    "            output_df.at[index, \"HIT_id\"] = row[\"_id\"]\n",
    "            output_df.at[index, \"batch_id\"] = row[\"batch_id\"]\n",
    "            output_df.at[index, \"taskSet_id\"] = row[\"taskSet_id\"]\n",
    "            output_df.at[index, \"worker_id\"] = row[\"worker_id\"]\n",
    "\n",
    "            output_df.at[index, \"claim_id\"] = row[\"references\"][j][\"claim_db_id\"]\n",
    "            output_df.at[index, \"claim\"] = row[\"references\"][j][\"claim\"]\n",
    "            output_df.at[index, \"table\"] = row[\"references\"][j][\"table\"]\n",
    "\n",
    "            output_df.at[index, \"label\"] = row[\"outputs\"][j][\"label\"]\n",
    "            output_df.at[index, \"header\"] = row[\"outputs\"][j][\"header\"]\n",
    "            output_df.at[index, \"events\"] = row[\"events\"][j]\n",
    "            index += 1\n",
    "\n",
    "    print(len(output_df))\n",
    "    \n",
    "elif task == \"claim_generation\": \n",
    "    \n",
    "    output_df = pd.DataFrame(columns=[\"HIT_id\", \"batch_id\", \"taskSet_id\", \"worker_id\", \"claim_id\", \"claim\", \"table\",\n",
    "                                      \"label\", \"adjusted_claim\", \"events\"])\n",
    "    index = 0\n",
    "    for i, row in annotations_df.iterrows():\n",
    "        for j in range(len(row[\"references\"])):\n",
    "\n",
    "            output_df.at[index, \"HIT_id\"] = row[\"_id\"]\n",
    "            output_df.at[index, \"batch_id\"] = row[\"batch_id\"]\n",
    "            output_df.at[index, \"taskSet_id\"] = row[\"taskSet_id\"]\n",
    "            output_df.at[index, \"worker_id\"] = row[\"worker_id\"]\n",
    "\n",
    "            output_df.at[index, \"claim_id\"] = row[\"references\"][j][\"claim_db_id\"]\n",
    "            output_df.at[index, \"claim\"] = row[\"references\"][j][\"claim\"]\n",
    "            output_df.at[index, \"table\"] = row[\"references\"][j][\"table\"]\n",
    "\n",
    "            output_df.at[index, \"adjusted_claim\"] = row[\"outputs\"][j][\"adjusted_claim\"]\n",
    "            output_df.at[index, \"label\"] = row[\"outputs\"][j][\"label\"]\n",
    "            output_df.at[index, \"events\"] = row[\"events\"][j]\n",
    "            index += 1\n",
    "\n",
    "    print(len(output_df))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats_df = output_df[['claim', 'table']].copy()\n",
    "print(len(set(stats_df[\"claim\"])))\n",
    "\n",
    "urls = [entry[\"url\"] for entry in stats_df[\"table\"]]\n",
    "print(len(set(urls)))\n",
    "\n",
    "html_table = [entry[\"html_table\"] for entry in stats_df[\"table\"]]\n",
    "print(len(set(html_table)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "\n",
    "for index, row in output_df.iterrows():\n",
    "    if row[\"label\"] not in [0, 1]: \n",
    "        continue\n",
    "    elif row[\"claim\"].strip() not in x:\n",
    "        x.append(row[\"claim\"].strip())\n",
    "\n",
    "for _x in x: \n",
    "    print(f\"* {_x}\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worker analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "worker_list = output_df[\"worker_id\"]\n",
    "print(f\"{len(list(set(worker_list)))} unique workers worked on the {len(annotations_df)} tasks.\")\n",
    "\n",
    "Counter(worker_list).most_common()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average annotation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_annotation_time(events: list): \n",
    "    first_timestamp = parser.isoparse(events[1]['timestamp'])\n",
    "    last_timestamp = parser.isoparse(events[len(events)-1]['timestamp'])\n",
    "\n",
    "    duration = last_timestamp - first_timestamp\n",
    "    minutes = (duration.seconds//60)\n",
    "    \n",
    "    return duration.seconds, minutes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_min = []\n",
    "duration_sec = []\n",
    "worker_list = []\n",
    "\n",
    "for index, row in annotations_df.iterrows(): \n",
    "    worker_id = row['worker_id']\n",
    "    if worker_id in worker_list:\n",
    "#         Uncomment rows below if we want to know time of non-first time workers\n",
    "        dur_sec, dur_min = calc_annotation_time(row[\"events\"])\n",
    "        duration_sec.append(dur_sec)\n",
    "        duration_min.append(dur_min)\n",
    "#         continue\n",
    "    else:\n",
    "        worker_list.append(worker_id)\n",
    "        dur_sec, dur_min = calc_annotation_time(row[\"events\"])\n",
    "        duration_sec.append(dur_sec)\n",
    "        duration_min.append(dur_min)\n",
    "        \n",
    "        \n",
    "# print boxplot of time duration for task \n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(16, 4))\n",
    "sns.boxplot(x=duration_min, ax = ax[0])\n",
    "sns.boxplot(x=duration_sec, ax = ax[1])\n",
    "\n",
    "ax[0].set_title('Time spent on one HIT (first time workers)')\n",
    "ax[1].set_title('Time spent on one HIT (first time workers)')\n",
    "ax[0].set(xlabel='time in minutes')\n",
    "ax[1].set(xlabel='time in seconds')\n",
    "\n",
    "\n",
    "print(pd.DataFrame(duration_min).describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'label': output_df[\"label\"]})\n",
    "ax = sns.barplot(x=df.label.value_counts().index, y=df.label.value_counts())\n",
    "\n",
    "s = 0\n",
    "for p in ax.patches:\n",
    "    s+= p.get_height()\n",
    "\n",
    "for p in ax.patches: \n",
    "    ax.text(p.get_x() + p.get_width()/2.,\n",
    "            p.get_height(),\n",
    "            '{}'.format(int(p.get_height())), \n",
    "            fontsize=12,\n",
    "            color='black',\n",
    "            ha='center',\n",
    "            va='bottom')\n",
    "\n",
    "ax.set_title('Distribution of labels')\n",
    "ax.set(xlabel='0 = supports | 1 = refutes | 2 = related but NEI | 3 = unrelated ', ylabel='annotations')\n",
    "# ax.set(xlabel='0 = supported | 1 = refuted ', ylabel='adjusted claims')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [TABLE ANNOTATION TASK] Majority voting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority(votes):\n",
    "    votes = [v for v in votes if v != -1]\n",
    "    if collections.Counter(votes).most_common(1)[0][1] == 1: \n",
    "        return -1\n",
    "    else:\n",
    "        return collections.Counter(votes).most_common(1)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_label_df = output_df[['HIT_id', 'claim_id','label','header']].copy()\n",
    "pre_label_df['label'] = pre_label_df['label'].apply(lambda x : [x])\n",
    "pre_label_df['header'] = pre_label_df['header'].apply(lambda x : [x] if x==-1 else x)\n",
    "pre_label_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pre_label_df.groupby(['claim_id', 'HIT_id']).agg({'label': \"sum\"}) \n",
    "label_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# label_df = pre_label_df.groupby(['claim_id', 'HIT_id']).agg('sum') \n",
    "# label_df = pre_label_df.groupby(['majority']).agg('sum')\n",
    "\n",
    "label_df = label_df.dropna()\n",
    "\n",
    "print(f\"Length before filtering for claims with three assignments: {len(label_df)}\")\n",
    "label_df = pd.DataFrame([row for index, row in label_df.iterrows() if len(row[\"label\"])==3])\n",
    "label_df['majority'] = label_df['label'].apply(majority)\n",
    "\n",
    "label_df = label_df.reset_index()\n",
    "print(len(label_df))\n",
    "label_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'label': label_df[\"majority\"]})\n",
    "ax = sns.barplot(x=df.label.value_counts().index, y=df.label.value_counts())\n",
    "\n",
    "s = 0\n",
    "for p in ax.patches:\n",
    "    s+= p.get_height()\n",
    "\n",
    "for p in ax.patches: \n",
    "    ax.text(p.get_x() + p.get_width()/2.,\n",
    "            p.get_height(),\n",
    "            '{}'.format(int(p.get_height())), \n",
    "            fontsize=12,\n",
    "            color='black',\n",
    "            ha='center',\n",
    "            va='bottom')\n",
    "\n",
    "ax.set_title('Distribution of labels')\n",
    "ax.set(xlabel='0 = supports | 1 = refutes | 2 = related but NEI | 3 = unrelated ', ylabel='claim-table pairs')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update majority voting label in final_dataset in DB (=> needed for claim generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ds_col = db.final_dataset\n",
    "\n",
    "cursor =  final_ds_col.find({})\n",
    "df = pd.DataFrame(list(cursor)) \n",
    "print(f\"Length of test set: {len(df)}\")\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many (claim, relevant_table) pairs we have in final_ds\n",
    "\n",
    "temp = [len(x) for x in df[\"table_relevant\"] if x and type(x) == list]\n",
    "sum(temp) # total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract from output_df all entries with majority voting \"2\" (=\"relevant\")\n",
    "\n",
    "x = []\n",
    "for claim_id, hit_id in list(label_df[label_df[\"majority\"]==2][\"index\"]):\n",
    "    x.append(output_df[(output_df[\"claim_id\"]==claim_id) & (output_df[\"HIT_id\"]==hit_id)].iloc[0,:])\n",
    "\n",
    "output_df_majority = pd.DataFrame(x)\n",
    "print(len(output_df_majority))\n",
    "output_df_majority.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update final_dataset collection in MongoDB \n",
    "# Add tables to column \"table_relevant\" in final_dataset\n",
    "\n",
    "counter = 0\n",
    "for index, row in df.iterrows(): # iterate over final_dataset\n",
    "    _id = str(row[\"_id\"])\n",
    "    \n",
    "    for i, r in output_df_majority.iterrows(): # iterate over claims with relevant tables (accord. to majority voting)\n",
    "        annotated_table = r[\"table\"]\n",
    "        change = 0\n",
    "        \n",
    "        if _id != r[\"claim_id\"]:\n",
    "            continue \n",
    "            \n",
    "        temp_list = row[\"table_relevant\"] if type(row[\"table_relevant\"]) == list else []\n",
    "        relevant_tables = []\n",
    "        for relevant_t in temp_list:\n",
    "            if \"_id\" in relevant_t:\n",
    "                relevant_t[\"id\"] = relevant_t[\"_id\"]\n",
    "                del relevant_t[\"_id\"]\n",
    "                \n",
    "            relevant_tables.append(relevant_t)\n",
    "        \n",
    "        if \"id\" in annotated_table: \n",
    "            if annotated_table[\"id\"] not in [t[\"id\"] for t in relevant_tables]:\n",
    "                relevant_tables.append(annotated_table)\n",
    "                change = 1\n",
    "                \n",
    "        elif \"_id\" in annotated_table: \n",
    "            if annotated_table[\"_id\"] not in [t[\"id\"] for t in relevant_tables]:\n",
    "                annotated_table[\"id\"] = annotated_table[\"_id\"].copy()\n",
    "                del annotated_table[\"_id\"]\n",
    "                relevant_tables.append(annotated_table)\n",
    "                change = 1\n",
    "\n",
    "        else: # find matching _id for annotated_table first\n",
    "            for table in row[\"tables\"]: \n",
    "\n",
    "                if table[\"rows_list\"] == annotated_table[\"rows_list\"]:\n",
    "                    not_added_before = False\n",
    "                    for tab in relevant_tables:\n",
    "                        if annotated_table[\"rows_list\"] == tab[\"rows_list\"]: \n",
    "                            not_added_before = True\n",
    "\n",
    "                    if not_added_before:\n",
    "                        annotated_table[\"id\"] = table[\"id\"]\n",
    "                        relevant_tables.append(annotated_table)\n",
    "                        change = 1\n",
    "\n",
    "        if change:\n",
    "            counter += 1\n",
    "            final_ds_col.update_one({'_id': row[\"_id\"]},\n",
    "                                    {'$set': {'table_relevant': relevant_tables}})\n",
    "\n",
    "counter\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update majority voting in claim_generation dataset (=> after adjusted claim annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_col = db.claim_generation\n",
    "cursor =  claim_col.find({})\n",
    "df = pd.DataFrame(list(cursor)) \n",
    "print(f\"Length of data set: {len(df)}\")\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['_id_str'] = df['_id'].astype('str')\n",
    "no_entries = []\n",
    "\n",
    "for index, row in label_df.iterrows(): \n",
    "    _id = row[\"index\"][0]\n",
    "    row_id = df.loc[df['_id_str'] == _id][\"_id\"]\n",
    "    \n",
    "    if len(row_id.values) == 0:\n",
    "        no_entries.append(row[\"index\"])\n",
    "        continue\n",
    "    \n",
    "#         Uncomment to update claim_generation collection in MongoDB\n",
    "#     claim_col.update_one({'_id': row_id.values[0]}, \n",
    "#                          {\n",
    "#                              '$set': {'majority_label': str(row[\"majority\"]), \n",
    "#                                       'majority_header': row[\"header\"]}\n",
    "#                          })\n",
    "\n",
    "print(len(no_entries))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_entries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# todo enter for ids in \"no_entries\" list the corrsponding claim table pair to the collection \"claim_generation\" in MongoDB\n",
    "\n",
    "for claim_id, hit_id in no_entries: \n",
    "    row = output_df.loc[(output_df['claim_id'] == claim_id) && (output_df['HIT_id'] == hit_id)]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Header rationales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_list = [len(entry) for entry in output_df[\"header\"] if (entry!=-1 and entry!=[])]\n",
    "df = pd.DataFrame({'label': label_list})\n",
    "# sns.histplot(data=label_list)\n",
    "\n",
    "ax = sns.barplot(x=df.label.value_counts().index, y=df.label.value_counts())\n",
    "\n",
    "s = 0\n",
    "for p in ax.patches:\n",
    "    s+= p.get_height()\n",
    "\n",
    "for p in ax.patches: \n",
    "    ax.text(p.get_x() + p.get_width()/2.,\n",
    "            p.get_height(),\n",
    "            '{}'.format(int(p.get_height())), \n",
    "            fontsize=11,\n",
    "            color='black',\n",
    "            ha='center',\n",
    "            va='bottom')\n",
    "    \n",
    "ax.set_title('Number of column rationales selected')\n",
    "ax.set(ylabel='count')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = []\n",
    "for index, row in annotations_df.iterrows():\n",
    "    for output in row[\"outputs\"]: \n",
    "        if output['label']==0:\n",
    "            workers.append(row[\"worker_id\"])\n",
    "            \n",
    "print(\"Workers + count of claims they selected header rationales for:\")\n",
    "Counter(workers).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [CLAIM GENERATION TASK] Adjusted Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_adjusted_claims = True\n",
    "claim_generation_col = db.claim_generation\n",
    "counter = 0\n",
    "\n",
    "if add_adjusted_claims:\n",
    "    for index, row in output_df.iterrows(): \n",
    "        if list(claim_generation_col.find({'claim': row[\"adjusted_claim\"]})) == []:\n",
    "            counter += 1\n",
    "            claim_generation_col.insert_one({\"_id\": uuid.uuid4(), \n",
    "                                             \"claim\": row[\"adjusted_claim\"],\n",
    "                                             \"table\": row[\"table\"],\n",
    "                                             \"label\": row[\"label\"],\n",
    "                                             \"initial_claim_id\": row[\"claim_id\"],\n",
    "                                             \"initial_claim\": row[\"claim\"]})\n",
    "print(counter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[entry for entry in annotations_df[\"feedback\"] if entry!=None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_list = [str(entry[\"label\"]) for annotation in annotations_df[\"outputs\"] for entry in annotation]\n",
    "df = pd.DataFrame({'label': output_df[\"label\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_pairs = {}\n",
    "for index, row in output_df.iterrows():\n",
    "    if row[\"label\"] == 2: \n",
    "        related_pairs[row[\"claim\"]] = [row[\"worker_id\"]]\n",
    "\n",
    "len(related_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(related_pairs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add output_df_majority to final dataset to balance NEI class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import jsonlines\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_majority.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# templates used for dataset creation\n",
    "\n",
    "entry_template = {\n",
    "    \"_id\": \"\", \n",
    "    \"claim\": \"\", \n",
    "    \"label\": \"\", \n",
    "    \"header_rationale\": \"\", \n",
    "    \"table\": \"\",\n",
    "    \"initial_claim\": \"\"\n",
    "}\n",
    "\n",
    "table_template = {\n",
    "    'website': \"\",\n",
    "    'website_title': \"\",\n",
    "    'caption': \"\",\n",
    "    'header_horizontal': \"\",\n",
    "    'header_vertical': \"\",\n",
    "    'rows': \"\",\n",
    "    'html_code': \"\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "\n",
    "dataset = []\n",
    "with jsonlines.open('data/dataset.jsonl') as reader:\n",
    "    for line in reader: \n",
    "        dataset.append(line)\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_claims = list(pd.DataFrame(dataset)[\"claim\"])\n",
    "len(list_of_claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict=[]\n",
    "\n",
    "#removing the duplicate entry\n",
    "for i in range(len(Langlist)): \n",
    "    if Langlist[i] not in Langlist[i + 1:]: \n",
    "        result_dict.append(Langlist[i]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset using templates\n",
    "\n",
    "for index, row in output_df_majority.iterrows():\n",
    "    if row[\"claim\"] in list_of_claims: \n",
    "        continue\n",
    "    else: \n",
    "        list_of_claims.append(row[\"claim\"])\n",
    "    \n",
    "    table = copy.deepcopy(table_template)\n",
    "    table[\"website\"] = row[\"table\"][\"url\"]\n",
    "    table[\"website_title\"] = row[\"table\"][\"title\"]\n",
    "    table[\"caption\"] = row[\"table\"][\"caption\"]\n",
    "    table[\"header_horizontal\"] = row[\"table\"][\"header_horizontal\"]\n",
    "    table[\"header_vertical\"] = row[\"table\"][\"header_vertical\"]\n",
    "    table[\"rows\"] = row[\"table\"][\"rows_list\"]\n",
    "    table[\"html_code\"] = row[\"table\"][\"html_table\"]\n",
    "    \n",
    "    entry = copy.deepcopy(entry_template)\n",
    "    entry[\"table\"] = table\n",
    "    entry[\"_id\"] = str(row[\"claim_id\"])\n",
    "    entry[\"claim\"] = row[\"claim\"]\n",
    "    entry[\"label\"] = \"NOT ENOUGH INFO\"\n",
    "    entry[\"header_rationale\"] = row[\"header\"]\n",
    "    entry[\"initial_claim\"] = row[\"claim\"]\n",
    "    \n",
    "    dataset.append(entry)\n",
    "\n",
    "print(len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(dataset.copy(), test_size=0.2)  \n",
    "testset, evalset = train_test_split(testset.copy(), test_size=0.5)  \n",
    "\n",
    "print(len(trainset))\n",
    "print(len(evalset))\n",
    "print(len(testset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "# save dataset in jsonl file \n",
    "\n",
    "# with jsonlines.open('data/dataset_balanced.jsonl', mode='w') as writer:\n",
    "#     writer.write_all(dataset)\n",
    "\n",
    "# with jsonlines.open('data/trainset.jsonl', mode='w') as writer:\n",
    "#     writer.write_all(trainset)\n",
    "\n",
    "# with jsonlines.open('data/evalset.jsonl', mode='w') as writer:\n",
    "#     writer.write_all(evalset)\n",
    "\n",
    "# with jsonlines.open('data/testset.jsonl', mode='w') as writer:\n",
    "#     writer.write_all(testset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
